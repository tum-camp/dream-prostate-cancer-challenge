{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This file is part of the submission of the Chair for Computer Aided\n",
    "Medical Procedures, Technische Universität München, Germany to the\n",
    "Prostate Cancer DREAM Challenge 2015.\n",
    "\n",
    "This program is free software: you can redistribute it and/or modify\n",
    "it under the terms of the GNU General Public License as published by\n",
    "the Free Software Foundation, either version 3 of the License, or\n",
    "(at your option) any later version.\n",
    "\n",
    "This program is distributed in the hope that it will be useful,\n",
    "but WITHOUT ANY WARRANTY; without even the implied warranty of\n",
    "MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n",
    "GNU General Public License for more details.\n",
    "\n",
    "You should have received a copy of the GNU General Public License\n",
    "along with this program.  If not, see <http://www.gnu.org/licenses/>."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Change the path to were the ARFF files produced by the `DREAM_Prostate_Cancer` notebook are located!__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "base_dir = \".\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Change the path to were the `survial` Python package is located!__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "from os.path import join, basename\n",
    "import re\n",
    "\n",
    "import numpy\n",
    "import pandas\n",
    "from pandas.rpy.common import convert_to_r_dataframe, convert_robj\n",
    "from pandas.core.common import is_categorical_dtype\n",
    "from rpy2.robjects.packages import importr\n",
    "import rpy2.robjects as ro\n",
    "from rpy2.robjects import r\n",
    "\n",
    "from survival.io import loadarff, writearff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%load_ext rpy2.ipython\n",
    "%R options(rf.cores = 4)\n",
    "_rfsrc = importr(\"randomForestSRC\")\n",
    "f = ro.Formula(\"Surv(LKADT_P, DEATH) ~ .\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ensure that attribute names don't contain any illegal characters such as `-`, `(`, or `)`, which get replaced by `.` in R and column names would not match anymore when retrieving results from R."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def safe_column_rename(table):\n",
    "    pat = re.compile(\"[)(-]\")\n",
    "    new_cols = {}\n",
    "    for col in table.columns:\n",
    "        new_cols[col] = pat.subn(\"_\", col)[0]\n",
    "    table.rename(columns=new_cols, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "studies = [\"ASCENT2\", \"CELGENE\", \"EFC6546\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# here's a nice wrapper to combine original data + imputed data\n",
    "r_impute = r('''combine.impute <- function(object) {\n",
    "    if (is.null(object$yvar))\n",
    "        impData <- object$xvar\n",
    "    else\n",
    "        impData <- cbind(object$yvar, object$xvar)\n",
    "\n",
    "    if (!is.null(object$imputed.indv)) {\n",
    "        impData[object$imputed.indv, ] <- object$imputed.data\n",
    "    }\n",
    "    impData\n",
    "}''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def load(study):\n",
    "    if study.endswith(\".arff\"):\n",
    "        filename = study\n",
    "    else:\n",
    "        filename = join(base_dir, \"%s.arff\" % study)\n",
    "    data = loadarff(filename).set_index(\"index\")\n",
    "    safe_column_rename(data)\n",
    "    return data\n",
    "\n",
    "\n",
    "def category_to_object(data):\n",
    "    for col in data.select_dtypes(include=['category']).columns:\n",
    "        data[col] = data[col].astype(object, copy=False)\n",
    "    return data\n",
    "\n",
    "def to_rdata(data):\n",
    "    data = category_to_object(data)\n",
    "    if \"DEATH\" in data.columns:\n",
    "        data[\"DEATH\"] = data[\"DEATH\"].astype(float)\n",
    "    rdata = convert_to_r_dataframe(data, strings_as_factors=True)\n",
    "    return rdata\n",
    "\n",
    "\n",
    "def impute(data):\n",
    "    rdata = to_rdata(data.copy())\n",
    "    rfmodel = _rfsrc.rfsrc(f, data=rdata, proximity=False, nsplit=25, ntree=2000, nimpute=5, importance=\"permute.ensemble\",\n",
    "                           na_action=\"na.impute\", seed=-121451)\n",
    "    imp_data = convert_robj(r_impute(rfmodel))\n",
    "\n",
    "    imp_data[\"DEATH\"] = data[\"DEATH\"]\n",
    "    return imp_data, rfmodel\n",
    "\n",
    "\n",
    "def load_and_impute(study):\n",
    "    data = load(study)\n",
    "    return impute(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "imputed_data = {}\n",
    "for study in studies:\n",
    "    print(study)\n",
    "    imputed_data[study] = load_and_impute(study)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "asc_model = imputed_data[\"ASCENT2\"][1]\n",
    "celg_model = imputed_data[\"CELGENE\"][1]\n",
    "ven_model = imputed_data[\"EFC6546\"][1]\n",
    "%Rpush asc_model celg_model ven_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%R\n",
    "pdf(\"ASCENT2.pdf\", 10, 20); plot(asc_model, plots.one.page=FALSE); dev.off();\n",
    "pdf(\"CELGENE.pdf\", 10, 20); plot(celg_model, plots.one.page=FALSE); dev.off();\n",
    "pdf(\"EFC6546.pdf\", 10, 20); plot(ven_model, plots.one.page=FALSE); dev.off();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i1 in range(len(studies)):\n",
    "    s1 = studies[i1]\n",
    "    for i2 in range(i1 + 1, len(studies)):\n",
    "        s2 = studies[i2]\n",
    "        name = \"%s_%s\" % (s1, s2)\n",
    "        print(name)\n",
    "\n",
    "        data = category_to_object(load(name))\n",
    "        print(\"Missing values before: %d\" % data.isnull().sum().sum())\n",
    "        data.fillna(imputed_data[s1][0], inplace=True)\n",
    "        data.fillna(imputed_data[s2][0], inplace=True)\n",
    "        n_missing = data.isnull().sum().sum()\n",
    "        print(\"Missing values after: %d\" % n_missing)\n",
    "        \n",
    "        if n_missing > 0:\n",
    "            imputed_data[name] = impute(data)\n",
    "        else:\n",
    "            imputed_data[name] = (data, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "name = \"_\".join(studies)\n",
    "data = category_to_object(load(name))\n",
    "print(\"Missing values before: %d\" % data.isnull().sum().sum())\n",
    "for s in studies:\n",
    "    data.fillna(imputed_data[s][0], inplace=True)\n",
    "\n",
    "for key, (df, model) in imputed_data.items():\n",
    "    if key not in studies:\n",
    "        data.fillna(df, inplace=True)\n",
    "\n",
    "n_missing = data.isnull().sum().sum()\n",
    "print(\"Missing values after: %d\" % n_missing)\n",
    "if n_missing > 0:\n",
    "    imputed_data[name] = impute(data)\n",
    "else:\n",
    "    imputed_data[name] = (data, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#asc_celg_model = imputed_data[\"ASCENT2_CELGENE\"][1]\n",
    "#asc_ven_model = imputed_data[\"ASCENT2_EFC6546\"][1]\n",
    "celg_ven_model = imputed_data[\"CELGENE_EFC6546\"][1]\n",
    "#all_model = imputed_data[\"ASCENT2_CELGENE_EFC6546\"][1]\n",
    "%Rpush celg_ven_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%R\n",
    "#pdf(\"ASCENT2_CELGENE.pdf\", 10, 20); plot(asc_celg_model, plots.one.page=FALSE); dev.off();\n",
    "#pdf(\"ASCENT2_EFC6546.pdf\", 10, 20); plot(asc_ven_model, plots.one.page=FALSE); dev.off();\n",
    "pdf(\"CELGENE_EFC6546.pdf\", 10, 20); plot(celg_ven_model, plots.one.page=FALSE); dev.off();\n",
    "#pdf(\"ASCENT2_CELGENE_EFC6546.pdf\", 10, 20); plot(all_model, plots.one.page=FALSE); dev.off();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def restore_categorical(imp_data, study):\n",
    "    if isinstance(study, pandas.DataFrame):\n",
    "        _data = study\n",
    "    else:\n",
    "        _data = load(study)\n",
    "    cat_columns = _data.select_dtypes(include=[\"category\"]).columns\n",
    "    for col in cat_columns:\n",
    "        if not is_categorical_dtype(imp_data[col].dtype):\n",
    "            rc = _data[col].cat\n",
    "            imp_data[col] = pandas.Categorical(imp_data[col].astype(\"object\"), categories=rc.categories,\n",
    "                                               ordered=rc.ordered)\n",
    "    return imp_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "drop_columns = [\"AGEGRP\", \"HEIGHTBL\", \"WEIGHTBL\"]\n",
    "for key, (df, model) in imputed_data.items():\n",
    "    df = restore_categorical(df, key)\n",
    "    if \"STUDYID\" in df.columns:\n",
    "        df = df.drop(\"STUDYID\", axis=1)\n",
    "    writearff(df.drop(drop_columns, axis=1), \"%s-imputed.arff\" % key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Impute Test Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Change the path to where the ARFF files produced by the code above have been written to!__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_base_dir = \".\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from dream_utils import transfer_categories\n",
    "\n",
    "label_cols = ['DEATH', 'LKADT_P', 'DISCONT', 'ENDTRS_C', 'ENTRT_PC']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# converting directly to R does not support categorical\n",
    "# and messes up categories that are not present, therefore\n",
    "# we have to align categories in R again\n",
    "r_align_factors = r('''align.factors <- function(train.data, test.data) {\n",
    "for (col in colnames(train.data)) {\n",
    "    if (!is.factor(train.data[, col]))\n",
    "        next\n",
    "\n",
    "    if (!(col %in% colnames(test.data))) {\n",
    "        next\n",
    "    }\n",
    "\n",
    "    lvl.train <- levels(train.data[, col])\n",
    "    lvl.test <- levels(test.data[, col])\n",
    "\n",
    "    if (length(setdiff(lvl.test, lvl.train)) > 0) {\n",
    "#        cat(paste(\"***\", \"test\", \"--->\", col, \"--->\", \"train\"))\n",
    "#        print(setdiff(lvl.test, lvl.train))\n",
    "        new.lvls <- union(lvl.train, lvl.test)\n",
    "\n",
    "        levels(train.data[, col]) <- new.lvls\n",
    "    }\n",
    "\n",
    "    if (length(setdiff(lvl.train, lvl.test)) > 0) {\n",
    "#        cat(paste(\"***\", \"train\", \"--->\", col, \"--->\", \"test\"))\n",
    "#        print(setdiff(lvl.train, lvl.test))\n",
    "        levels(test.data[, col]) <- lvl.train\n",
    "    }\n",
    "}\n",
    "return(list(train=train.data, test=test.data))\n",
    "}''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def impute_test(train_data, test_data):\n",
    "#    for col in test_data:\n",
    "#        if is_categorical_dtype(test_data[col]):\n",
    "#            print(col)\n",
    "#            print(test_data[col].cat.categories);print(train_data[col].cat.categories)\n",
    "    \n",
    "    print(\"%d missing values\" % test_data.isnull().sum().sum())\n",
    "    rtrain = to_rdata(train_data)\n",
    "    rtest = to_rdata(test_data)\n",
    "    rdata = r_align_factors(rtrain, rtest)\n",
    "\n",
    "    rf_model = _rfsrc.rfsrc(f, data=rdata.rx2(\"train\"), proximity=False, nsplit=10, importance=\"none\", seed=-121451)\n",
    "    rpred = r[\"predict\"](rf_model, newdata=rdata.rx2(\"test\"), **{\"na.action\": \"na.impute\", \"importance\": \"none\"})\n",
    "    imp_data = r_impute(rpred)\n",
    "\n",
    "    return convert_robj(imp_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def drop_missing_in_test(train_all):\n",
    "    cols = train_all.columns - label_cols\n",
    "    test_missing = test_data.loc[:, cols].apply(lambda x: pandas.isnull(x).sum())\n",
    "    test_missing /= test_data.shape[0]\n",
    "    not_in_test_cols = test_missing[test_missing == 1].index\n",
    "    print(\"Drop %d columns\" % len(not_in_test_cols))\n",
    "\n",
    "    c = train_all.columns.isin(not_in_test_cols)\n",
    "    return train_all.drop(train_all.columns[c], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_data = load(join(base_dir, \"dream_test_all.arff\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dat_orig = load(\"_\".join(studies))\n",
    "discont_not_missing = dat_orig.index[dat_orig.DISCONT.notnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for key in [\"ASCENT2\", \"CELGENE\", \"EFC6546\", \"ASCENT2_CELGENE\", \"ASCENT2_EFC6546\", \"CELGENE_EFC6546\", \"ASCENT2_CELGENE_EFC6546\"]:\n",
    "    print(key)\n",
    "    filename = \"%s-imputed.arff\" % key\n",
    "    dat_train = load(join(train_base_dir, filename))\n",
    "    idx = dat_train.index.isin(discont_not_missing)\n",
    "\n",
    "    dat_train = drop_missing_in_test(dat_train)\n",
    "\n",
    "    cols = dat_train.columns - label_cols\n",
    "    assert cols.isin(test_data.columns).all()\n",
    "    print(dat_train.shape)\n",
    "    writearff(dat_train.drop(['DISCONT', 'ENDTRS_C', 'ENTRT_PC'], axis=1), \"train_q1_\" + filename)\n",
    "    writearff(dat_train.drop(['DEATH', 'LKADT_P'], axis=1).loc[idx, :], \"train_q2_\" + filename)\n",
    "\n",
    "    dat_test = test_data.loc[:, cols]\n",
    "    dat_train.drop(['DISCONT', 'ENDTRS_C', 'ENTRT_PC'], axis=1, inplace=True)\n",
    "    dat_test, updates = transfer_categories(\n",
    "        dat_train, dat_test)\n",
    "    assert len(updates) == 0\n",
    "\n",
    "    imp_data = impute_test(dat_train.copy(), dat_test.copy())\n",
    "    imp_data_cat = restore_categorical(imp_data, dat_train.drop(['DEATH', 'LKADT_P'], axis=1))\n",
    "\n",
    "    writearff(imp_data_cat, \"test_\" + filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
