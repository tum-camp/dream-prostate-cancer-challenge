{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This file is part of the submission of the Chair for Computer Aided\n",
    "Medical Procedures, Technische Universität München, Germany to the\n",
    "Prostate Cancer DREAM Challenge 2015.\n",
    "\n",
    "This program is free software: you can redistribute it and/or modify\n",
    "it under the terms of the GNU General Public License as published by\n",
    "the Free Software Foundation, either version 3 of the License, or\n",
    "(at your option) any later version.\n",
    "\n",
    "This program is distributed in the hope that it will be useful,\n",
    "but WITHOUT ANY WARRANTY; without even the implied warranty of\n",
    "MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n",
    "GNU General Public License for more details.\n",
    "\n",
    "You should have received a copy of the GNU General Public License\n",
    "along with this program.  If not, see <http://www.gnu.org/licenses/>."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Change the path to where the challenges raw data is located!__ Data must be gzipped."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "base_dir = '../../prostate_cancer_challenge/data_training'\n",
    "test_base_dir = '../../prostate_cancer_challenge/data_final_scoring'\n",
    "tables = ['CoreTable_{0}.csv.gz', 'LesionMeasure_{0}.csv.gz',\n",
    "          'PriorMed_{0}.csv.gz', 'LabValue_{0}.csv.gz',\n",
    "          'MedHistory_{0}.csv.gz', 'VitalSign_{0}.csv.gz']\n",
    "filenames = [s.format('training') for s in tables]\n",
    "test_filenames = [s.format('validation') for s in tables]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Change the path to were the `survial` Python package is located!__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import itertools\n",
    "from os.path import join\n",
    "\n",
    "import numpy\n",
    "import pandas\n",
    "\n",
    "from dream_utils import *\n",
    "from survival.io import writearff\n",
    "from survival.util import safe_concat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_csv(filename, extra_na_values=[]):\n",
    "    return pandas.read_csv(filename, quoting=csv.QUOTE_NONNUMERIC, index_col=None,\n",
    "                           na_values=[\"\", \".\"] + extra_na_values, encoding='latin1', low_memory=False,\n",
    "                           compression='gzip')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Core Table\n",
    "\n",
    "It includes dependent variables for the 2 Subchallenges as well as summarized clinical covariates. These clinical covariates are created from sets of standardized longitudinal data tables (including but not limited to the 5 longitudinal data tables released for the Challenge) which cover information about demographics, co-existing disease conditions, prior treatment of the tumor and other co-existing conditions, important baseline lab results and vital sign, lesion measure and early response to therapy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ecog_value_map = {0: 'Fully active',\n",
    "                  1: 'Restricted activity',\n",
    "                  2: 'No activity', 3: 'No activity', 4: 'No activity'}\n",
    "#                  2: 'No activity, capable of selfcare',\n",
    "#                  3: 'limited selfcare',\n",
    "#                  4: 'bed bound'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_core_table(filename, drop_columns=None, log_transform_columns=None):\n",
    "    core_full = read_csv(filename)\n",
    "    core_full.rename(columns={'NA.': 'NA'}, inplace=True)\n",
    "    core_full.replace({'ECOG_C': ecog_value_map}, inplace=True)\n",
    "    if drop_columns is not None:\n",
    "        core_full.drop(drop_columns, axis=1, inplace=True)\n",
    "\n",
    "    height_labels = ['>=140-160', '>=160-180', '>=180-200']\n",
    "    if pandas.isnull(core_full.HGTBLCAT).all():\n",
    "        core_full.HGTBLCAT = pandas.cut(core_full.HEIGHTBL, [0, 160, 180, float('inf')], labels=height_labels)\n",
    "    else:\n",
    "        raw_height = pandas.Categorical(core_full.HGTBLCAT, categories=height_labels, ordered=True)\n",
    "        core_full.HGTBLCAT = raw_height\n",
    "\n",
    "    bins = [0,] + list(range(50, 141, 10)) + [(float('inf'))]\n",
    "    weight_labels = [\">=40-50\"]\n",
    "    for i in range(1, len(bins) - 2):\n",
    "        weight_labels.append(\">=%d-%d\" % (bins[i], bins[i + 1]))\n",
    "    weight_labels.append(\">=140-150\")\n",
    "\n",
    "    if pandas.isnull(core_full.WGTBLCAT).all():\n",
    "        core_full.WGTBLCAT = pandas.cut(core_full.WEIGHTBL, bins, labels=weight_labels)\n",
    "    else:\n",
    "        raw_weight = pandas.Categorical(core_full.WGTBLCAT, categories=weight_labels, ordered=True)\n",
    "        core_full.WGTBLCAT = raw_weight\n",
    "\n",
    "    age_labels = [\"18-64\", \"65-74\", \">=75\"]\n",
    "    if pandas.isnull(core_full.AGEGRP2).all():\n",
    "        bins = [18, 65, 75, float('inf')]\n",
    "        age_num = core_full.AGEGRP.replace({\">=85\": \"85\"}).astype(int)\n",
    "        core_full.AGEGRP2 = pandas.cut(age_num, bins, labels=age_labels)\n",
    "    else:\n",
    "        raw_age = pandas.Categorical(core_full.AGEGRP2, categories=age_labels, ordered=True)\n",
    "        core_full.AGEGRP2 = pandas.Series(raw_age)\n",
    "\n",
    "    if \"GLEAS_DX\" in core_full.columns:\n",
    "        gleason_score_labels = numpy.arange(2, 11, dtype=int).astype(numpy.unicode)\n",
    "        codes = core_full.GLEAS_DX.map(lambda x: int(x)-2 if pandas.notnull(x) else -1)\n",
    "        raw_gleas = pandas.Categorical.from_codes(codes, categories=gleason_score_labels, ordered=True, name=\"GLEAS_DX\")\n",
    "        core_full.GLEAS_DX = pandas.Series(raw_gleas)\n",
    "\n",
    "    if \"ECOG_C\" in core_full.columns:\n",
    "        core_full.ECOG_C = pandas.Categorical(core_full.ECOG_C,\n",
    "                                              categories=[\"Fully active\", \"Restricted activity\", \"No activity\"],\n",
    "                                              ordered=True)\n",
    "\n",
    "    visceral_mask = (core_full.LUNGS == 'Y') | (core_full.LIVER == 'Y') | (core_full.ADRENAL == 'Y') | (core_full.PANCREAS.astype(object) == 'Y')\n",
    "    visceral_metastases = pandas.Series('N', index=core_full.index, name=\"Visceral Metastases\")\n",
    "    visceral_metastases[visceral_mask] = 'Y'\n",
    "    core_full[\"Visceral Metastases\"] = visceral_metastases\n",
    "\n",
    "    cols = core_full.columns.to_series()\n",
    "    start_idx = int(numpy.flatnonzero(cols == 'NON_TARGET'))\n",
    "    core_full.iloc[:, start_idx:] = core_full.iloc[:, start_idx:].fillna('N')\n",
    "\n",
    "    treatment = pandas.Series(index=core_full.index, name=\"Treatment\", dtype=object)\n",
    "    has_docetaxel = pandas.notnull(core_full.TRT2_ID)\n",
    "    has_prednisone = pandas.notnull(core_full.TRT3_ID)\n",
    "    core_full.drop([\"TRT1_ID\", \"TRT2_ID\", \"TRT3_ID\"], axis=1, inplace=True)\n",
    "\n",
    "    treatment[(has_docetaxel) | (has_prednisone)] = \"DOCETAXEL or PREDNISONE\"\n",
    "    treatment.fillna('PLACEBO', inplace=True)\n",
    "    core_full[\"Treatment\"] = pandas.Series(pandas.Categorical(treatment, ordered=False))\n",
    "\n",
    "    core_full.set_index('RPT', inplace=True)\n",
    "\n",
    "    if core_full['DEATH'].notnull().any():\n",
    "        core_q1_labels = core_full.loc[:, ['DEATH', 'LKADT_P']]\n",
    "        death = core_full.DEATH == 'YES'\n",
    "        core_q1_labels['DEATH'] = pandas.Categorical(death.astype(int), ordered=False)\n",
    "        core_full.drop(['DEATH', 'LKADT_P'], axis=1, inplace=True)\n",
    "    else:\n",
    "        core_q1_labels = None\n",
    "\n",
    "    if core_full['DISCONT'].notnull().any():\n",
    "        core_q2_labels = core_full.loc[:, ['DISCONT', 'ENDTRS_C', 'ENTRT_PC']]\n",
    "        discont = numpy.zeros(core_q2_labels.shape[0], dtype=int)\n",
    "        discont[(core_q2_labels[\"DISCONT\"] == 1).values] = 1\n",
    "        discont[core_q2_labels[\"DISCONT\"].isnull().values] = -1\n",
    "        core_q2_labels['DISCONT'] = pandas.Categorical.from_codes(discont, categories=[\"0\", \"1\"], ordered=False)\n",
    "        core_full.drop(['DISCONT', 'ENDTRS_C', 'ENTRT_PC'], axis=1, inplace=True)\n",
    "    else:\n",
    "        core_q2_labels = None\n",
    "\n",
    "    if log_transform_columns is None:\n",
    "        log_columns, _ = detect_and_correct_skewness(core_full)\n",
    "    else:\n",
    "        log_transform(core_full, log_transform_columns, inplace=True)\n",
    "        log_columns = log_transform_columns\n",
    "    print(\"Log-transformed %d columns\" % len(log_columns))\n",
    "    \n",
    "    return core_full, core_q1_labels, core_q2_labels, log_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "other_cols = ['PER_REF', 'LKADT_REF', 'LKADT_PER', 'DOMAIN']\n",
    "core, train_q1_labels, train_q2_labels, core_log_transform = read_core_table(join(base_dir, filenames[0]),\n",
    "                                                                             other_cols)\n",
    "\n",
    "core_useless_cols = get_useless_columns(core)\n",
    "core.drop(core_useless_cols[core_useless_cols].index, axis=1, inplace=True)\n",
    "core.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "f = join(test_base_dir, test_filenames[0])\n",
    "core_test, _, _, _ = read_core_table(f, other_cols, log_transform_columns=core_log_transform)\n",
    "core_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PriorMed\n",
    "\n",
    "It includes all medications a patient took or has taken before first treatment of the trial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def check_units_consistency(table, groupby_col, unit_col):\n",
    "    n_units = table.loc[:, [groupby_col, unit_col]].groupby(groupby_col).aggregate(lambda x: x[unit_col].nunique())\n",
    "    if (n_units.iloc[:, 0] >= 2).any():\n",
    "        print(n_units[n_units.iloc[:, 0] >= 2])\n",
    "        raise ValueError('Measurements have multiple units')\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_routes(series):\n",
    "    d = {'INHALATION, NASAL, BOTH (IHNB)': 'INHALATION',\n",
    "     'INHALATION, ORAL (IHO)': 'INHALATION',\n",
    "     'INHALATION, UNSPECIFIED (IH)': 'INHALATION',\n",
    "     'INTRAMUSCULAR (IM)': 'INTRAMUSCULAR',\n",
    "     'INTRAVENOUS (IV)': 'INTRAVENOUS',\n",
    "     'INTRAVENOUS (NOT OTHERWISE SPECIFIED)': 'INTRAVENOUS',\n",
    "     'ORAL (PO)': 'ORAL',\n",
    "     'PER RECTAL (PR)': 'RECTAL',\n",
    "     'SUBCUTANEOUS (SC)': 'SUBCUTANEOUS'}\n",
    "    return series.replace(d).replace(\" \\(.+\\) ?\", regex=True, value=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def fix_chemical_class(table, inplace=False):\n",
    "    d = {'ACE INHIBITORS': ['ACE INHIBITORS AND CALCIUM CHANNEL BLOCKERS',\n",
    "                            'ACE INHIBITORS AND DIURETICS',\n",
    "                            'ACE INHIBITORS, PLAIN',\n",
    "                            'ACE INHIBITORS, COMBINATIONS'],\n",
    "         'ANALGESICS': ['OTHER ANALGESICS AND ANTIPYRETICS'],\n",
    "         'ANTIINFLAMMATORY PREPARATIONS': ['ANTIINFL. PREP., NON-STEROIDS FOR TOPICAL USE',\n",
    "                                           'ANTIINFLAMMATORY PREPARATIONS, NON-STEROIDS FOR TO'],\n",
    "         'ANTIINFLAMMATORY AGENTS, NON-STEROIDS': ['ANTIINFLAMM/ANTIRHEUMATIC PRODUCTS, NON-STEROID',\n",
    "                                                   'OTHER ANTIINFL./ANTIRHEUMATIC AGENTS, NON-STEROIDS',\n",
    "                                                   'OTHER ANTIINFLAMMATORY AND ANTIRHEUMATIC AGENTS, N',\n",
    "                                                   'ANTIINFLAMMATORY AND ANTIRHEUMATIC PRODUCTS, NON-S',\n",
    "                                                   'OTHER ANTIINFLAM/ANTIRHEUMATIC AGENTS,NON-STEROIDS'],\n",
    "         'ANTIINFLAMMATORY PREPARATIONS': ['ANTIINFLAM PREPS, NON-STEROIDS FOR TOPICAL USE'],\n",
    "         'ANTIINFLAMMATORY PRODUCTS FOR VAGINAL ADMINISTRAT.': ['ANTIINFLAMMATORY PRODUCTS FOR VAGINAL ADMINISTRATI'],\n",
    "         'ANGIOTENSIN II ANTAGONISTS': ['ANGIOTENSIN II ANTAGONISTS AND DIURETICS',\n",
    "                                        'ANGIOTENSIN II ANTAGONISTS, PLAIN',\n",
    "                                        'ANGIOTENSIN II ANTAGONISTS, COMBINATIONS',\n",
    "                                        'ANGIOTENSIN II ANTAGONISTS AND CALCIUM CHANNEL BLO'],\n",
    "         'ANTI-ANDROGENS': ['ANTIANDROGENS, PLAIN'],\n",
    "         'ANTIHISTAMINES': ['ANTIHISTAMINES FOR TOPICAL USE',\n",
    "                            'OTHER ANTIHISTAMINES FOR SYSTEMIC USE',\n",
    "                            'ETHERS, CHEMICALLY CLOSE TO ANTIHISTAMINES'],\n",
    "         'ASCORBIC ACID (VITAMIN C)': ['ASCORBIC ACID (VITAMIN C), COMBINATIONS',\n",
    "                                       'ASCORBIC ACID (VITAMIN C), PLAIN'],\n",
    "         'BARBITURATES': ['BARBITURATES AND DERIVATIVES',\n",
    "                          'BARBITURATES, COMBINATIONS',\n",
    "                          'BARBITURATES, PLAIN'],\n",
    "         'BELLADONNA ALKALOIDS': ['BELLADONNA ALKALOIDS, SEMISYNTHETIC, QUATERNARY AM',\n",
    "                                  'BELLADONNA ALKALOIDS, TERTIARY AMINES',\n",
    "                                  'BELLADONNA ALKALOIDS,SEMISYNTH,QUATERN AMMON COMPS'],\n",
    "         'BENZODIAZEPINE RELATED DRUGS': ['BENZODIAZEPINE DERIVATIVES'],\n",
    "         'BETA BLOCKING AGENTS': ['BETA BLOCKING AGENTS, SELECTIVE',\n",
    "                                  'BETA BLOCKING AGENTS, NON-SELECTIVE',\n",
    "                                  'BETA BLOCKING AGENTS, SELECTIVE, AND OTHER ANTIHYP',\n",
    "                                  'BETA BLOCKING AGENTS, SELECTIVE, AND THIAZIDES',\n",
    "                                  'BETA BLOCKING AGENTS,SELECTIVE,AND OTHER DIURETICS',\n",
    "                                  'BETA BLOCKING AGENTS, SELECTIVE, AND OTHER DIURETI',\n",
    "                                  'B BLOCKING AGENT,SELECTIVE/OTHER ANTIHYPERTENSIVE',\n",
    "                                  'BETA BLOCKING AGENTS AND OTHER DIURETICS'],\n",
    "         'BIGUANIDES': ['BIGUANIDES AND AMIDINES'],\n",
    "         'CORTICOSTEROIDS': ['CORTICOSTEROIDS, WEAK (GROUP I)'],\n",
    "         'CALCIUM': ['CALCIUM COMPOUNDS',\n",
    "                     'CALCIUM, COMBINATIONS WITH OTHER DRUGS'],\n",
    "         'COMB AND COMPL. OF ALUMIN., CALC. AND MAGNES. COMP': ['COMBINATIONS AND COMPLEXES OF ALUMINIUM, CALCIUM A',\n",
    "                                                                'COMB/COMPLEXES ALUMINIUM, CALCIUM, MAGNESIUM COMPS'],\n",
    "         'COMB OF SULFONAMIDES/TRIMETHOPRIM INCL DERIVATIVES': ['COMBINATIONS OF SULFONAMIDES AND TRIMETHOPRIM, INC',\n",
    "                                                                'COMB.SULFONAMIDES & TRIMETHOPRIM INCL. DERIVATIVES'],\n",
    "         'CORTICOSTEROIDS': ['CORTICOSTEROIDS ACTING LOCALLY',\n",
    "                             'CORTICOSTEROIDS FOR LOCAL ORAL TREATMENT',\n",
    "                             'CORTICOSTEROIDS, COMBINATIONS FOR TREATMENT OF ACN',\n",
    "                             'CORTICOSTEROIDS, MODERATELY POTENT (GROUP II)',\n",
    "                             'CORTICOSTEROIDS, PLAIN',\n",
    "                             'CORTICOSTEROIDS, POTENT (GROUP III)',\n",
    "                             'CORTICOSTEROIDS, WEAK (GROUP I)',\n",
    "                             'CORTICOSTEROIDS FOR SYSTEMIC USE, COMBINATIONS',\n",
    "                             'CORTICOSTEROIDS, POTENT, OTHER COMBINATIONS',\n",
    "                             'CORTICOSTEROIDS, VERY POTENT (GROUP IV)',\n",
    "                             'CORTICOSTEROIDS, MODERAT. POTENT, COMB W/ANTIBIOT.'],\n",
    "         'FOLIC ACID AND DERIVATIVES': ['FOLIC ACID ANALOGUES'],\n",
    "         'GONADOTROPIN-RELEASING HORMONES': ['GONADOTROPIN RELEASING HORMONE ANALOGUES'],\n",
    "         'GENERAL NUTRIENTS': ['OTHER NUTRIENTS', 'OTHER COMBINATIONS OF NUTRIENTS'],\n",
    "         'HMG COA REDUCTASE INHIBITORS': ['HMG COA REDUCTASE INHIBITORS IN COMBINATION WITH O',\n",
    "                                          'HMG COA REDUCTASE INHIBITORS, OTHER COMBINATIONS'],\n",
    "         'HYPNOTICS AND SEDATIVES': ['HYPNOTICS & SEDATIVES COMB., EXCL BARBITURATES'],\n",
    "         'IMIDAZOLE DERIVATIVES': ['IMIDAZOLE AND TRIAZOLE DERIVATIVES'],\n",
    "         'INSULINS AND ANALOGUES': ['INSULINS AND ANALOGUES, LONG-ACTING',\n",
    "                                    'INSULINS AND ANALOGUES FOR INJECTION, FAST-ACTING',\n",
    "                                    'INSULINS AND ANALOGUES FOR INJECTION, INTERMEDIATE',\n",
    "                                    'INSULINS AND ANALOGUES FOR INJECTION, LONG-ACTING',\n",
    "                                    'INSULINS AND ANALOGUES FOR INHALATION',\n",
    "                                    'INSULINS AND ANALOGUES, FAST-ACTING',\n",
    "                                    'INSULINS AND ANALOGUES, INTERMEDIATE-ACTING',\n",
    "                                    'INSULINS AND ANAL.,INTERM.-ACTING,COMB.W/FAST ACT.',\n",
    "                                    'INSULINS AND ANALOGUES FOR INJ,INTERMEDIATE-ACTING',\n",
    "                                    'INSULINS/ANALOGUES FOR INJ,INTERMED-ACT+FAST-ACTIN'],\n",
    "         'IRON TRIVALENT': ['IRON TRIVALENT, ORAL PREPARATIONS',\n",
    "                            'IRON TRIVALENT, PARENTERAL PREPARATIONS'],\n",
    "         'LAXATIVES': ['CONTACT LAXATIVES', 'OSMOTICALLY ACTING LAXATIVES'],\n",
    "         'MAGNESIUM': ['MAGNESIUM COMPOUNDS', 'MAGNESIUM COMPS'],\n",
    "         'MULTIVITAMINS': ['MULTIVITAMINS WITH MINERALS',\n",
    "                           'MULTIVITAMINS, OTHER COMBINATIONS',\n",
    "                           'MULTIVITAMINS, PLAIN'],\n",
    "         'OPIUM ALKALOIDS': ['NATURAL OPIUM ALKALOIDS',\n",
    "                             'OPIUM ALKALOIDS AND DERIVATIVES',\n",
    "                             'OPIUM DERIVATIVES AND EXPECTORANTS'],\n",
    "         'QUINOLINE DERIVATIVES': ['QUININE AND DERIVATIVES'],\n",
    "         'SULFONAMIDES': ['SULFONAMIDES, PLAIN',\n",
    "                          'SULFONAMIDES, UREA DERIVATIVES'],\n",
    "         'SEROTONIN ANTAGONISTS': ['SELECTIVE SEROTONIN (5HT1) AGONISTS',\n",
    "                                   'SEROTONIN (5HT3) ANTAGONISTS'],\n",
    "         'SYNT ANTICHOLIN,ESTERS WITH TERTIARY AMINO GROUP': ['SYNTH ANTICHOLINERGICS,ESTERS/TERTIARY AMINO GROUP'],\n",
    "         'THIAZIDES': ['THIAZIDES AND POTASSIUM IN COMBINATION', 'THIAZIDES, PLAIN'],\n",
    "         'ANESTHETICS': ['OPIOID ANESTHETICS',\n",
    "                         'ANESTHETICS, GENERAL',\n",
    "                         'ANESTHETICS FOR TOPICAL USE',\n",
    "                         'ANESTHETICS, LOCAL'],\n",
    "         'ADRENERGICS AND OTH.DRUGS FOR OBSTRUCT.AIRWAY DIS.': ['ADRENERGICS AND OTH.DRUGS FOR OBSTRUC.AIRWAY DISEA',\n",
    "                                                                'ADRENERGICS AND OTHER DRUGS FOR OBSTRUCTIVE AIRWAY',\n",
    "                                                                'ADRENERGICS/OTHER DRUGS FOR OBSTR AIRWAY DISEASES',\n",
    "                                                                'ADRENERGIC AND DOPAMINERGIC AGENTS'],\n",
    "         'AGENTS FOR TREATMENT OF HEMORRHOIDS': ['OTHER AGENTS FOR TREATMENT OF HEMORRHOIDS AND ANAL',\n",
    "                                                 'TREATMENT OF HEMORRHOIDS+ANAL FISSURES,TOPICAL USE'],\n",
    "         'AMINO ACIDS': ['AMINO ACIDS AND DERIVATIVES',\n",
    "                         'AMINO ACIDS, INCL. COMBINATIONS WITH POLYPEPTIDES'],\n",
    "         'ANTACIDS': ['ANTACIDS WITH ANTIFLATULENTS',\n",
    "                      'ANTACIDS WITH SODIUM BICARBONATE',\n",
    "                      'ANTACIDS, OTHER COMBINATIONS'],\n",
    "         'ANTIARRHYTHMICS': ['ANTIARRHYTHMICS, CLASS IA',\n",
    "                             'ANTIARRHYTHMICS, CLASS IC',\n",
    "                             'ANTIARRHYTHMICS, CLASS III'],\n",
    "         'ANTIDEPRESSANTS': ['ANTIDEPRESSANTS IN COMBINATION WITH PSYCHOLEPTICS',\n",
    "                             'OTHER ANTIDEPRESSANTS'],\n",
    "         'ANTIBIOTICS': ['OTHER ANTIBIOTICS FOR TOPICAL USE',\n",
    "                         'COMBINATIONS OF PENICILLINS, INCL. BETA-LACTAMASE',\n",
    "                         'BETA-LACTAMASE RESISTANT PENICILLINS',\n",
    "                         'PENICILLINS WITH EXTENDED SPECTRUM',\n",
    "                         'FIRST-GENERATION CEPHALOSPORINS',\n",
    "                         'THIRD-GENERATION CEPHALOSPORINS',\n",
    "                         'COMBS OF PENICILLINS INCL BETA-LACTAMASE INHIBITOR',\n",
    "                         'COMB OF PENICILLINS, INCL. BETA-LACTAMASE INHIB.'],\n",
    "         'ANTICHOLINERGICS': ['SYNTHETIC ANTICHOLINERGICS',\n",
    "                              'SYNTHETIC ANTICHOLINERGIC AGENTS IN COMBINATION WI',\n",
    "                              'SYNTHETIC ANTICHOLINERGICS, ESTERS WITH TERTIARY A',\n",
    "                              'SYNTHETIC ANTICHOLINERGICS, QUATERNARY AMMONIUM CO',\n",
    "                              'SYNTHETIC ANTICHOLINERGICS, ESTERS WITH TERTIARY A'],\n",
    "         'ANTIINFECTIVES': ['ANTIINFECT. AND ANTISEPT. FOR LOCAL ORAL TREATMENT',\n",
    "                            'ANTIINFECTIVES AND ANTISEPTICS FOR LOCAL ORAL TREA',\n",
    "                            'OTHER ANTIINFECTIVES',\n",
    "                            'OTHER ANTIINFECTIVES AND ANTISEPTICS'],\n",
    "         'ESTROGENS': ['NATURAL AND SEMISYNTHETIC ESTROGENS, PLAIN',\n",
    "                       'SYNTHETIC ESTROGENS, PLAIN'],\n",
    "         'HEPARINS': ['HEPARIN GROUP', 'HEPARINS OR HEPARINOIDS FOR TOPICAL USE'],\n",
    "         'PHENOTHIAZINES': ['PHENOTHIAZINE DERIVATIVES',\n",
    "                            'PHENOTHIAZINES WITH ALIPHATIC SIDE-CHAIN',\n",
    "                            'PHENOTHIAZINES WITH PIPERAZINE STRUCTURE'],\n",
    "         'LIPID MODIFYING AGENTS': ['OTHER LIPID MODIFYING AGENTS'],\n",
    "         'NUCLEOSIDE REVERSE TRANSCRIPTASE INHIBITORS': ['NUCLEOSIDES AND NUCLEOTIDES EXCL REV.TRANSCR.INHIB',\n",
    "                                                         'NUCLEOSIDES AND NUCLEOTIDES EXCL. REVERSE TRANSCRI'],\n",
    "         'OTHER THERAPEUTIC PRODUCTS': ['ALL OTHER THERAPEUTIC PRODUCTS'],\n",
    "         'OTHER DRUGS AFFECTING BONE STRUCTURE AND MINERALIZ': ['OTHER DRUG AFFECTING BONE STRUCTURE/MINERALIZATION'],\n",
    "         'SYMPATHOMIMETICS': ['SYMPATHOMIMETICS IN GLAUCOMA THERAPY','SYMPATHOMIMETICS, PLAIN'],\n",
    "         'VITAMINS': ['VITAMINS WITH MINERALS', 'VITAMINS, OTHER COMBINATIONS', 'COMBINATIONS OF VITAMINS'],\n",
    "         'VITAMIN B-COMPLEX': ['VITAMIN B-COMPLEX WITH VITAMIN C',\n",
    "                               'VITAMIN B-COMPLEX, PLAIN',\n",
    "                               'VITAMIN B-COMPLEX, INCL. COMBINATIONS',\n",
    "                               'VITAMIN B-COMPLEX WITH MINERALS',\n",
    "                               'VITAMIN B-COMPLEX, OTHER COMBINATIONS'],\n",
    "         'XANTHINES': ['XANTHINE DERIVATIVES'],\n",
    "         'ZINC': ['ZINC BANDAGES', 'ZINC PRODUCTS'],\n",
    "        }\n",
    "    replace = {}\n",
    "    for key, items in d.items():\n",
    "        for item in items:\n",
    "            replace[item] = key\n",
    "    return table.replace(replace, inplace=inplace, regex=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_med(group):\n",
    "    duration_val = group['CMDURN']\n",
    "    duration_comp = (group['CMENDT_PC'] - group['CMSTDT_PC']).abs()\n",
    "    duration_val = duration_val.fillna(duration_comp)\n",
    "\n",
    "    duration = duration_val.mean() if duration_val.notnull().any() else numpy.nan\n",
    "    n_meds = group.shape[0]\n",
    "\n",
    "    return pandas.Series({\"size\": n_meds,\n",
    "                          \"duration\": duration})\n",
    "\n",
    "def safe_has_yes(x):\n",
    "    if x.isnull().all():\n",
    "        return False\n",
    "    return (x == 'YES').any()\n",
    "\n",
    "\n",
    "def discretize_duration(table):\n",
    "    intervals = {\"HORMONOTHERAPY duration\": {\"interval\": 365, \"max\": 3},\n",
    "                 \"OPIUM ALKALOIDS duration\": {\"interval\": 30.5, \"max\": 2},\n",
    "                 \"GONADOTROPIN-RELEASING HORMONES duration\": {\"interval\": 365, \"max\": 3},\n",
    "                 \"GLUCOCORTICOIDS duration\": {\"interval\": 30.5, \"max\": 2},\n",
    "                 \"BISPHOSPHONATES duration\": {\"interval\": 365, \"max\": 2},\n",
    "                 \"ANTI-ANDROGENS duration\": {\"interval\": 365, \"max\": 3}}\n",
    "\n",
    "    def _discretize(x):\n",
    "        if x.name not in intervals:\n",
    "            return x\n",
    "        x_positive = x[x > 0]\n",
    "\n",
    "        bins = numpy.concatenate((numpy.arange(intervals[x.name][\"max\"] + 1, dtype=float), [float(\"inf\")]))\n",
    "        val = intervals[x.name][\"interval\"]\n",
    "        unit = \"years\" if val == 365 else \"months\"\n",
    "        labels = [\"<1 \" + unit]\n",
    "        for i in range(1, len(bins) - 2):\n",
    "            labels.append(\"%d-%d %s\" % (bins[i], bins[i + 1], unit))\n",
    "        labels.append(\">=%d %s\" % (bins[-2], unit))\n",
    "\n",
    "        v = pandas.cut(x_positive.floordiv(val), bins, labels=labels, include_lowest=True, right=False)\n",
    "        codes = numpy.zeros(x.shape, dtype=int)\n",
    "        codes[numpy.where(x > 0)] = v.cat.codes + 1\n",
    "        labels = [\"NONE\"] + labels\n",
    "\n",
    "        x_new = pandas.Series(pandas.Categorical.from_codes(codes, categories=labels, ordered=True),\n",
    "                              index=x.index, name=x.name)\n",
    "        return x_new\n",
    "    \n",
    "    return table.apply(_discretize, reduce=False)\n",
    "         \n",
    "\n",
    "def read_priormed_table(filename, chem_classes_included=None, routes_included=None):\n",
    "    med_dirty = read_csv(filename, extra_na_values=[\"...\"])\n",
    "\n",
    "    med = fix_chemical_class(med_dirty)\n",
    "    med.CMSCAT.replace({\"HORMONAL THERAPY\": \"HORMONOTHERAPY\"}, inplace=True)\n",
    "\n",
    "    do_drop_useless = chem_classes_included is None\n",
    "    if do_drop_useless:\n",
    "        chem_classes = med.cmatc4.value_counts()\n",
    "        chem_classes_included = chem_classes[chem_classes > 60]\n",
    "        \n",
    "        routes = get_routes(med.CMROUTE).value_counts()\n",
    "        routes_included = routes[routes > 10]\n",
    "\n",
    "#    if intents_included is None:\n",
    "#        intents = med.CMINTENT.value_counts()\n",
    "#        intents_included = intents[intents > 100]\n",
    "\n",
    "    check_units_consistency(med, 'cmatc4', 'CMDURU')\n",
    "        \n",
    "    chemical_mask = med.cmatc4.isin(chem_classes_included.index)\n",
    "    assert chemical_mask.any()\n",
    "    chemical_grouped = med[chemical_mask].groupby(['RPT', 'cmatc4'])\n",
    "\n",
    "    s = chemical_grouped.apply(get_med).reset_index()\n",
    "\n",
    "    n_meds = s.pivot(index='RPT', columns='cmatc4', values='size')\n",
    "    n_meds.fillna(value=0, inplace=True)\n",
    "\n",
    "    duration = s.pivot(index='RPT', columns='cmatc4', values='duration')\n",
    "    duration_unique = duration.apply(lambda x: x.nunique())\n",
    "    duration.drop((duration_unique[duration_unique < 80]).index, axis=1, inplace=True)\n",
    "    duration.fillna(value=0, inplace=True)\n",
    "\n",
    "    diuretics = med_dirty.loc[:, [\"RPT\", \"cmatc4\"]].groupby('RPT').agg(\n",
    "        lambda x: x.str.contains(\"DIURET\").any())\n",
    "    diuretics.rename(columns={\"cmatc4\": \"DIURETICS\"}, inplace=True)\n",
    "\n",
    "    routes_mask = med.CMROUTE.isin(routes_included.index)\n",
    "    assert routes_mask.any()\n",
    "    routes_grouped = med[routes_mask].groupby(['RPT', 'CMROUTE']).size()\n",
    "    routes_grouped.name = 'size'\n",
    "    s = routes_grouped.reset_index().pivot(index='RPT', columns='CMROUTE', values='size')\n",
    "    has_route = (s > 0)\n",
    "\n",
    "#    intent_mask = med.CMINTENT.isin(intents_included.index)\n",
    "#    assert intent_mask.any()\n",
    "#    intent_grouped = med[intent_mask].groupby(['RPT', 'CMINTENT'])\n",
    "\n",
    "#    s = intent_grouped.apply(get_med).reset_index()\n",
    "#    n_intents = s.pivot(index='RPT', columns='CMINTENT', values='size')\n",
    "#    n_intents.fillna(value=0, inplace=True)\n",
    "\n",
    "#    intent_duration = s.pivot(index='RPT', columns='CMINTENT', values='duration')\n",
    "#    intent_duration.fillna(value=0, inplace=True)\n",
    "\n",
    "    hormone_grouped = med[med.CMSCAT == \"HORMONOTHERAPY\"].groupby(['RPT']).apply(get_med)\n",
    "    horomontherapy = pandas.Series(False, index=hormone_grouped.index)\n",
    "    horomontherapy[hormone_grouped[\"size\"] > 0] = True\n",
    "    hormone_grouped[\"HORMONOTHERAPY\"] = horomontherapy\n",
    "    hormone_grouped[\"duration\"].fillna(0, inplace=True)\n",
    "    hormone_grouped = hormone_grouped.drop(\"size\", axis=1).rename(columns={\"duration\": \"HORMONOTHERAPY duration\"})\n",
    "\n",
    "    if not do_drop_useless:\n",
    "        d = chem_classes_included.index.difference(n_meds.columns)\n",
    "        new_meds = pandas.DataFrame(0, index=n_meds.index, columns=d)\n",
    "        n_meds = safe_concat((n_meds, new_meds), axis=1)\n",
    "\n",
    "        new_duration = pandas.DataFrame(0, index=duration.index, columns=d)\n",
    "        duration = safe_concat((duration, new_duration), axis=1)\n",
    "        \n",
    "        d = routes_included.index.difference(has_route.columns)\n",
    "        new_routes = pandas.DataFrame(False, index=has_route.index, columns=d)\n",
    "        has_route = safe_concat((has_route, new_routes), axis=1)\n",
    "\n",
    "    pre_meds = safe_concat(((n_meds > 0),\n",
    "                            diuretics,\n",
    "                            duration.add_suffix(' duration'),\n",
    "                            has_route,\n",
    "                            hormone_grouped), axis=1)\n",
    "    pre_meds = discretize_duration(pre_meds)\n",
    "\n",
    "    adverse_event = med.loc[:, ['RPT', 'CM_AE']].groupby('RPT').aggregate(safe_has_yes)\n",
    "    pre_meds['Treatment for Adverse Event'] = adverse_event.astype(bool)\n",
    "\n",
    "    n_chem_classes = med.loc[:, ['RPT', 'cmatc4']].groupby('RPT').aggregate(lambda x: x.nunique())\n",
    "    pre_meds['Total chemical classes'] = safe_anscombe(n_chem_classes)\n",
    "\n",
    "#    total_intents = med.loc[:, ['RPT', 'CMINTENT']].groupby('RPT').aggregate(lambda x: x.nunique())\n",
    "#    pre_meds['Total intents'] = total_intents\n",
    "\n",
    "    def _fillna(x):\n",
    "        if pandas.core.common.is_numeric_dtype(x.dtype):\n",
    "            return x.fillna(0)\n",
    "        elif pandas.core.common.is_categorical_dtype(x.dtype):\n",
    "            return x.fillna(x.cat.categories[0])\n",
    "        else:\n",
    "            return x.fillna(False)\n",
    "\n",
    "    pre_meds = pre_meds.apply(_fillna, axis=0)\n",
    "\n",
    "    if do_drop_useless:\n",
    "        drop_useless(pre_meds, suffix=[\"duration\"], inplace=True)\n",
    "        mask = chem_classes_included.index.isin(pre_meds.columns)\n",
    "        chem_classes_included = chem_classes_included[mask]\n",
    "\n",
    "        mask = routes_included.index.isin(pre_meds.columns)\n",
    "        routes_included = routes_included[mask]\n",
    "\n",
    "    return pre_meds, chem_classes_included, routes_included"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def write_csv(counts, fp):\n",
    "    start = \"\"\n",
    "    for i in counts.index:\n",
    "        val = counts.loc[i]\n",
    "        if start != i[0]:\n",
    "            start = i[0]\n",
    "            fp.write(\"\\t\\n\")\n",
    "        if pandas.isnull(val):\n",
    "            val = 0\n",
    "        fp.write(\"\\\"%s\\\"\\t%d\\n\" % (i, val))\n",
    "\n",
    "def write_premed_chemical_classes():\n",
    "    ll = read_csv(join(base_dir, filenames[2]), extra_na_values=[\"...\"])\n",
    "    ll_test = read_csv(join(test_base_dir, test_filenames[2]), extra_na_values=[\"...\"])\n",
    "    fix_chemical_class(ll, inplace=True)\n",
    "    fix_chemical_class(ll_test, inplace=True)\n",
    "\n",
    "    m = [ll.STUDYID == \"ASCENT2\",\n",
    "         ll.STUDYID == \"CELGENE\",\n",
    "         ll.STUDYID == \"EFC6546\"]\n",
    "\n",
    "    cc = ll_test.loc[:, \"cmatc4\"].value_counts()\n",
    "    cv = cc.sort_index()\n",
    "\n",
    "    for m1 in m:\n",
    "        df = ll.loc[m1, [\"cmatc4\", \"CMSCAT\", \"STUDYID\"]]\n",
    "        cc = df.cmatc4.value_counts()\n",
    "        cv_new = cc.sort_index()\n",
    "        cv = pandas.concat((cv, cv_new), axis=1)\n",
    "\n",
    "    cv = cv.sum(axis=1)\n",
    "    with open(\"premed-all.csv\", \"w\") as fp:\n",
    "        write_csv(cv, fp)\n",
    "\n",
    "    return cv\n",
    "\n",
    "#chem_list = write_premed_chemical_classes()\n",
    "#chem_list.sort(ascending=False)\n",
    "#chem_list.head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pre_meds, chem_classes_included, routes_included = read_priormed_table(join(base_dir, filenames[2]))\n",
    "print(pre_meds.shape)\n",
    "chem_classes_included"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pre_meds_test, _, _ = read_priormed_table(join(test_base_dir, test_filenames[2]),\n",
    "                                       chem_classes_included,\n",
    "                                       routes_included)\n",
    "pre_meds_test = pre_meds_test.loc[:, pre_meds.columns]\n",
    "pre_meds_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LabValue\n",
    "\n",
    "It includes all lab tests a patient took from screening up to 84 days after first treatment date."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check that measurement unit is consistent among all patients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fix_testosterone_limits(lab):\n",
    "    \"\"\"Fix wrong reference ranges in TESTO by using original reference range instead of standardized\n",
    "    \n",
    "    See http://support.sagebase.org/sagebase/topics/unusually-high-reference-range-limits-in-labvalue-table#reply_15637022\n",
    "    \"\"\"\n",
    "    patient_ids = (lab.RPT.isin(['VEN-951001401', 'VEN-951001601'])) & (lab.LBTESTCD == 'TESTO')\n",
    "    lab.loc[patient_ids, ['LBSTNRLO', 'LBSTNRHI']] = lab.loc[patient_ids, ['LBORNRLO', 'LBORNRHI']].values\n",
    "    return lab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fix_total_bilirubin_limits(lab):\n",
    "    \"\"\"Fix wrong upper reference limits of total bilirubin measurements.\n",
    "\n",
    "    Values have already been converted from mg/dl to UMOL/L (1 mg/dl = 17.1 UMOL/L)\n",
    "\n",
    "    See http://support.sagebase.org/sagebase/topics/unusually-high-reference-range-limits-in-labvalue-table#reply_15660569\n",
    "    \"\"\"\n",
    "    patient_ids = (lab.LBTESTCD == 'TBILI') & (lab.LBSTNRHI > 185)\n",
    "\n",
    "    lab.loc[patient_ids, 'LBSTNRHI'] = lab.loc[patient_ids, 'LBORNRHI'].values\n",
    "    return lab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_range(x, mean_value):\n",
    "    ref_range = x.loc[:, ['LBSTNRLO', 'LBSTNRHI']]\n",
    "#    rr = ref_range.apply(lambda y: y.nunique())\n",
    "#    assert (rr < 2).all()\n",
    "\n",
    "    # we assume that for each patient and marker, the reference ranges\n",
    "    # are the same for all measurements\n",
    "    rr = ref_range.iloc[0, :]\n",
    "    m = pandas.notnull(rr)\n",
    "    if m.all():\n",
    "        if mean_value < rr['LBSTNRLO']:\n",
    "            b = 'lowered'\n",
    "        elif mean_value > rr['LBSTNRHI']:\n",
    "            b = 'elevated'\n",
    "        else:\n",
    "            b = 'normal'\n",
    "    elif m[0]:\n",
    "        # only lower limit\n",
    "        if mean_value <= rr['LBSTNRLO']:\n",
    "            b = 'normal'\n",
    "        else:\n",
    "            b = 'elevated'\n",
    "    elif m[1]:\n",
    "        # only upper limit\n",
    "        if mean_value <= rr['LBSTNRHI']:\n",
    "            b = 'normal'\n",
    "        else:\n",
    "            b = 'elevated'\n",
    "    else:\n",
    "        b = None\n",
    "\n",
    "    return b\n",
    "\n",
    "def safe_mean(x):\n",
    "    # check if we can convert string result to float,\n",
    "    # otherwise use numeric result\n",
    "    try:\n",
    "        v = x['LBSTRESC'].astype(float)\n",
    "    except ValueError:\n",
    "        try:\n",
    "            # strip smaller sign from start\n",
    "            v = x['LBSTRESC'].str.lstrip('<').astype(float)\n",
    "        except ValueError:\n",
    "            # fallback to integer value\n",
    "            v = x['LBSTRESN']\n",
    "\n",
    "    mean_value = v.mean()\n",
    "    b = get_range(x, mean_value)\n",
    "\n",
    "    return pandas.Series({'value': mean_value, 'range': b})\n",
    "\n",
    "\n",
    "def impute_testo_range(lab_baseline):\n",
    "    def get_most_common(x):\n",
    "        v = x.value_counts()\n",
    "        if len(v) == 0:\n",
    "            return numpy.nan\n",
    "        else:\n",
    "            return v.index[0]\n",
    "\n",
    "    m = lab_baseline.LBTESTCD == 'TESTO'\n",
    "    common = lab_baseline.loc[m, ['STUDYID', 'LBSTNRLO', 'LBSTNRHI']].groupby('STUDYID').aggregate(get_most_common)\n",
    "    common.dropna(inplace=True)\n",
    "\n",
    "    tofill = pandas.DataFrame(index=lab_baseline.index, columns=['LBSTNRLO', 'LBSTNRHI'])\n",
    "    for row in range(common.shape[0]):\n",
    "        value = common.iloc[row, :]\n",
    "        study = common.index[row]\n",
    "\n",
    "        tofill.loc[m & (lab_baseline.STUDYID == study), :] = value.values\n",
    "\n",
    "    return lab_baseline.fillna(tofill)\n",
    "\n",
    "\n",
    "def aggregate_categorical(x, categories):\n",
    "    scat = pandas.Categorical(x[\"LBSTRESC\"].values, categories=categories[x.name[1]],\n",
    "                                            ordered=True)\n",
    "    return pandas.Series({\"value\": scat.max()})\n",
    "\n",
    "\n",
    "def to_ordered_categorical(x, categories):\n",
    "    if isinstance(categories, dict):\n",
    "        categories = categories[x.name]\n",
    "    categories = pandas.Index(categories)\n",
    "    m = categories.isin(pandas.Index(x.unique()))\n",
    "    return pandas.Series(pandas.Categorical(x.values, categories=categories[m], ordered=True),\n",
    "                         name=x.name, index=x.index)\n",
    "\n",
    "\n",
    "def read_labvalue_table(filename, lab_tests_included=None, log_transform_columns=None, date_quantiles=None):\n",
    "    lab = read_csv(filename)\n",
    "    lab_baseline_mask = lab.LBBLFL == 'Y'\n",
    "    lab_baseline = lab[lab_baseline_mask]\n",
    "\n",
    "    # Fix issues\n",
    "    lab_baseline.loc[lab_baseline.LBTEST == 'SODIUM', 'LBTESTCD'] = 'SODIUM'\n",
    "    fix_testosterone_limits(lab_baseline)\n",
    "    fix_total_bilirubin_limits(lab_baseline)\n",
    "    lab_baseline = impute_testo_range(lab_baseline)\n",
    "\n",
    "    check_units_consistency(lab_baseline, 'LBTESTCD', 'LBSTRESU')\n",
    "\n",
    "    do_drop_useless = lab_tests_included is None\n",
    "    if do_drop_useless:\n",
    "        lab_tests = lab_baseline.LBTESTCD.value_counts()\n",
    "        lab_tests_included = lab_tests[lab_tests > 100]\n",
    "\n",
    "    lab_tests_categories = {\"BACT\": [\"1+\", \"2+\", \"3+\", \"4+\"],\n",
    "                            \"EPISQCE\": [\"1+\", \"2+\", \"3+\", \"4+\"],\n",
    "                            \"MUCTHR\": [\"1+\", \"2+\", \"3+\", \"4+\"],\n",
    "                            \"OCCBLD\": [\"NEGATIVE\", \"TRACE\", \"SMALL\", \"MODERATE\", \"LARGE\"],\n",
    "                            \"RBCQL\": [\"ABSENT\", \"+\", \"++\", \"+++\"],\n",
    "                            \"WBCQL\": [\"ABSENT\", \"+\", \"++\", \"+++\"],\n",
    "                            \"PH\": ['5', '5.5', '6', '6.5', '7', '7.5', '8', '8.5']}\n",
    "    tests_categorical = list(lab_tests_categories.keys())\n",
    "\n",
    "    mask = lab_baseline.LBTESTCD.isin(lab_tests_included.index.difference(tests_categorical))\n",
    "    columns = ['RPT', 'LBTESTCD', 'LBSTRESC', 'LBSTRESN', 'LBSTNRLO', 'LBSTNRHI', 'LBDT_PC']\n",
    "    lab_grouped = lab_baseline.loc[mask, columns].groupby(['RPT', 'LBTESTCD'])\n",
    "\n",
    "    s = lab_grouped.apply(safe_mean).reset_index()\n",
    "    pre_lab_values = s.pivot(index='RPT', columns='LBTESTCD', values='value')\n",
    "\n",
    "    mask_cat = lab_baseline.LBTESTCD.isin(tests_categorical)\n",
    "    cat_grouped = lab_baseline.loc[mask_cat, ['RPT', 'LBTESTCD', 'LBSTRESC']].groupby(['RPT', 'LBTESTCD'])\n",
    "    s_cat = cat_grouped.apply(lambda x: aggregate_categorical(x, lab_tests_categories))\n",
    "    pre_lab_cat = s_cat.reset_index().pivot(index='RPT', columns='LBTESTCD', values='value')\n",
    "    pre_lab_cat = pre_lab_cat.apply(lambda x: to_ordered_categorical(x, lab_tests_categories))\n",
    "\n",
    "    pre_lab_ranges = s.pivot(index='RPT', columns='LBTESTCD', values='range')\n",
    "    pre_lab_ranges[pandas.isnull(pre_lab_values)] = \"NONE\"\n",
    "    pre_lab_ranges = pre_lab_ranges.apply(lambda x: to_ordered_categorical(x, [\"NONE\", \"lowered\", \"normal\", \"elevated\"]))\n",
    "\n",
    "    mask_all = lab_baseline.LBTESTCD.isin(lab_tests_included.index)\n",
    "    n_date = lab_baseline.loc[mask_all, ['RPT', 'LBTESTCD', 'LBDT_PC']].groupby(['RPT', 'LBTESTCD']).min()\n",
    "\n",
    "    pre_lab_dates = n_date.reset_index().pivot(index='RPT', columns='LBTESTCD', values='LBDT_PC')\n",
    "    # Split date into quartiles\n",
    "    if date_quantiles is None:\n",
    "        pre_lab_dates, date_quantiles = cut_quantiles(pre_lab_dates, 4)\n",
    "    else:\n",
    "        pre_lab_dates, _ = cut_quantiles(pre_lab_dates, date_quantiles)\n",
    "\n",
    "    if log_transform_columns is None:\n",
    "        log_columns, new_columns = detect_and_correct_skewness(pre_lab_values)\n",
    "    else:\n",
    "        log_trans_cols = pre_lab_values.columns.intersection(log_transform_columns)\n",
    "        _, new_columns = log_transform(pre_lab_values, log_trans_cols, inplace=True)\n",
    "        log_columns = log_trans_cols\n",
    "\n",
    "    print(\"Log-transformed %d columns\" % len(log_columns))\n",
    "    pre_lab_ranges.rename(columns=new_columns, inplace=True)\n",
    "    pre_lab_dates.rename(columns=new_columns, inplace=True)\n",
    "\n",
    "    pre_lab = safe_concat((pre_lab_values,\n",
    "                           pre_lab_cat,\n",
    "                           pre_lab_ranges.add_suffix(' range'),\n",
    "                           pre_lab_dates.add_suffix(' date')), axis=1)\n",
    "\n",
    "#    pre_lab['N lab tests'] = safe_anscombe(lab_baseline.groupby('RPT').size())\n",
    "\n",
    "    if do_drop_useless:\n",
    "        drop_useless(pre_lab, suffix=[\"range\", \"date\"], inplace=True)\n",
    "    \n",
    "    return pre_lab, lab_tests_included, log_columns, date_quantiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pre_lab, lab_tests_included, lab_tests_log_columns, lab_tests_date_quantiles = read_labvalue_table(join(base_dir, filenames[3]))\n",
    "print(pre_lab.shape)\n",
    "lab_tests_included"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pre_lab_test, _, _, _ = read_labvalue_table(join(test_base_dir, test_filenames[3]),\n",
    "                                      lab_tests_included, lab_tests_log_columns, lab_tests_date_quantiles)\n",
    "pre_lab_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VitalSign\n",
    "\n",
    "It includes all vital sign a patient took from screening up to 84 days after reference day."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert height to centimeters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def convert_height_to_cm(vitals_baseline):\n",
    "    height_inch_mask = (vitals_baseline.VSTESTCD == 'HEIGHT') & (vitals_baseline.VSSTRESU == 'IN')\n",
    "    vitals_baseline.loc[height_inch_mask, 'VSSTRESC'] = vitals_baseline.loc[height_inch_mask, 'VSSTRESC'].astype(float) * 2.54\n",
    "    vitals_baseline.loc[height_inch_mask, 'VSSTRESU'] = 'CM'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert weight to kilogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def convert_weight_to_kg(vitals_baseline):\n",
    "    weight_lbs_mask = (vitals_baseline.VSTESTCD == 'WEIGHT') & (vitals_baseline.VSSTRESU != 'KG')\n",
    "    vitals_baseline.loc[weight_lbs_mask, 'VSSTRESC'] = vitals_baseline.loc[weight_lbs_mask, 'VSSTRESC'].astype(float) * 0.45359237\n",
    "    vitals_baseline.loc[weight_lbs_mask, 'VSSTRESU'] = 'KG'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert temperature to °C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def convert_temp_to_c(vitals_baseline):\n",
    "    temp_f_mask = (vitals_baseline.VSTESTCD == 'TEMP') & (vitals_baseline.VSSTRESU == '°F')\n",
    "    vitals_baseline.loc[temp_f_mask, 'VSSTRESC'] = (vitals_baseline.loc[temp_f_mask, 'VSSTRESC'].astype(float) - 32) / 1.8\n",
    "    vitals_baseline.loc[temp_f_mask, 'VSSTRESU'] = '°C'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_vitals(group):\n",
    "    df = group.loc[:, ['VSTESTCD', 'VSSTRESC']]\n",
    "    df.VSSTRESC = df.VSSTRESC.astype(float)\n",
    "    g = df.groupby('VSTESTCD')\n",
    "    res = g.mean()\n",
    "    res.loc['Date Collected', :] = group['VSDT_PC'].mean()\n",
    "    return res\n",
    "\n",
    "\n",
    "def read_vitalsign_table(filename, vitals_included=None, date_quantiles=None):\n",
    "    vitals = read_csv(filename)\n",
    "    vitals_baseline_mask = vitals.VSBLFL == 'Y'\n",
    "    vitals_baseline = vitals[vitals_baseline_mask]\n",
    "    \n",
    "    convert_height_to_cm(vitals_baseline)\n",
    "    convert_weight_to_kg(vitals_baseline)\n",
    "    convert_temp_to_c(vitals_baseline)\n",
    "    \n",
    "    check_units_consistency(vitals_baseline, 'VSTESTCD', 'VSSTRESU')\n",
    "\n",
    "    do_drop_useless = vitals_included is None\n",
    "    if do_drop_useless:\n",
    "        vitals_included = vitals_baseline['VSTESTCD'].unique()\n",
    "\n",
    "    columns = ['RPT', 'VSTESTCD', 'VSSTRESC', 'VSDT_PC']\n",
    "    vitals_grouped = vitals_baseline.loc[:, columns].groupby('RPT')\n",
    "    s = vitals_grouped.apply(get_vitals)\n",
    "    pre_vitals = s.reset_index().pivot(index='RPT', columns='VSTESTCD', values='VSSTRESC')\n",
    "\n",
    "    if 'WEIGHT' in pre_vitals.columns and 'HEIGHT' in pre_vitals.columns:\n",
    "        pre_vitals['BMI'] = pre_vitals.WEIGHT / (pre_vitals.HEIGHT * pre_vitals.HEIGHT) * 10000\n",
    "\n",
    "    if \"ECOG\" in pre_vitals.columns:\n",
    "        pre_vitals.replace({'ECOG': ecog_value_map}, inplace=True)\n",
    "        pre_vitals[\"ECOG\"] = pandas.Categorical(pre_vitals[\"ECOG\"],\n",
    "                                                categories=[\"Fully active\", \"Restricted activity\", \"No activity\"],\n",
    "                                                ordered=True)\n",
    "\n",
    "    # Split date into quartiles\n",
    "    if date_quantiles is None:\n",
    "        pre_vitals_date, date_quantiles = cut_quantiles(pre_vitals[\"Date Collected\"], 4)\n",
    "    else:\n",
    "        pre_vitals_date, _ = cut_quantiles(pre_vitals[\"Date Collected\"], date_quantiles)\n",
    "    pre_vitals[\"Date Collected\"] = pre_vitals_date\n",
    "\n",
    "    if do_drop_useless:\n",
    "        vitals_useless = get_useless_columns(pre_vitals)\n",
    "        pre_vitals.drop(vitals_useless[vitals_useless].index, axis=1, inplace=True)\n",
    "    \n",
    "    return pre_vitals, vitals_included, date_quantiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pre_vitals, vitals_included, vitals_date_quantiles = read_vitalsign_table(join(base_dir, filenames[5]))\n",
    "print(pre_vitals.shape)\n",
    "vitals_included"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pre_vitals_test, _, _ = read_vitalsign_table(join(test_base_dir, test_filenames[5]),\n",
    "                                             vitals_included, vitals_date_quantiles)\n",
    "print(pre_vitals_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MedHistory\n",
    "\n",
    "It includes all medical diagnoses patients provided at screening, which covers co-existing conditions patients have.\n",
    "\n",
    "*Missing data*: ASCENT2 trial did not provide event level medical history table, it only provided summary level pre-specified co-morbidity variables, which have been included in CoreTable. Therefore, there are no event level data for ASCENT2 in MedicalHistory table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def read_medhistory_table(filename, diagnosis_included=None, date_quantiles=None):\n",
    "    comorb = read_csv(filename)\n",
    "\n",
    "    replace = {\"INGUINAL HERNIA REPAIR\": \"INGUINAL HERNIA\",\n",
    "               \"CATARACT OPERATION\": \"CATARACT\",\n",
    "               \"ABDOMINAL PAIN LOWER\": \"ABDOMINAL PAIN\",\n",
    "               \"ABDOMINAL PAIN UPPER\": \"ABDOMINAL PAIN\",\n",
    "               \"ALCOHOL ABUSE\": \"ALCOHOLISM\",\n",
    "               \"ALCOHOL DETOXIFICATION\": \"ALCOHOLISM\",\n",
    "               \"ALCOHOLIC\": \"ALCOHOLISM\",\n",
    "               \"ANXIETY DISORDER\": \"ANXIETY\",\n",
    "               \"ANAEMIA MACROCYTIC\": \"ANAEMIA\",\n",
    "               \"ANGINA UNSTABLE\": \"ANGINA PECTORIS\",\n",
    "               \"ARTERIOSCLEROSIS CORONARY ARTERY\": \"ARTERIOSCLEROSIS\",\n",
    "               \"BLADDER CANCER STAGE 0, WITH CANCER IN SITU\": \"BLADDER CANCER\",\n",
    "               \"BLADDER NECK OBSTRUCTION\": \"BLADDER OBSTRUCTION\",\n",
    "               \"BLADDER NECK OPERATION\": \"BLADDER OPERATION\",\n",
    "               \"BLADDER OUTLET OBSTRUCTION\": \"BLADDER OBSTRUCTION\",\n",
    "               \"BRONCHITIS CHRONIC\": \"BRONCHITIS\",\n",
    "               \"BUNDLE BRANCH BLOCK LEFT\": \"BUNDLE BRANCH BLOCK\",\n",
    "               \"BUNDLE BRANCH BLOCK RIGHT\": \"BUNDLE BRANCH BLOCK\",\n",
    "               \"CARDIAC FAILURE CHRONIC\": \"CARDIAC FAILURE\",\n",
    "               \"CARDIAC FAILURE CONGESTIVE\": \"CARDIAC FAILURE\",\n",
    "               \"CENTRAL VENOUS CATHETERISATION\": \"CATHETERISATION VENOUS\",\n",
    "               \"CHOLECYSTITIS ACUTE\": \"CHOLECYSTITIS\",\n",
    "               \"CHOLECYSTITIS CHRONIC\": \"CHOLECYSTITIS\",\n",
    "               \"CIRCUMCISED\": \"CIRCUMCISION\",\n",
    "               \"COLON CANCER STAGE I\": \"COLON CANCER\",\n",
    "               \"COLOSTOMY CLOSURE\": \"COLOSTOMY\",\n",
    "               \"CONJUNCTIVITIS ALLERGIC\": \"CONJUNCTIVITIS\",\n",
    "               \"DIVERTICULUM INTESTINAL\": \"DIVERTICULUM\",\n",
    "               \"DYSPNOEA EXERTIONAL\": \"DYSPNOEA\",\n",
    "               \"GASTRITIS EROSIVE\": \"GASTRITIS\",\n",
    "               \"MALIGNANT MELANOMA IN SITU\": \"MALIGNANT MELANOMA\",\n",
    "               \"PERCUTANEOUS CORONARY INTERVENTION\": \"CORONARY ANGIOPLASTY\",\n",
    "               \"PROSTATE CANCER METASTATIC\": \"PROSTATE CANCER\",\n",
    "               \"SQUAMOUS CELL CARCINOMA OF SKIN\": \"SQUAMOUS CELL CARCINOMA\",\n",
    "               \"TOBACCO ABUSE\": \"TOBACCO USER\",\n",
    "               \"TYPE 2 DIABETES MELLITUS\": \"DIABETES MELLITUS\",}\n",
    "\n",
    "    comorb.MHDECOD.replace(replace, inplace=True)\n",
    "\n",
    "    do_drop_useless = diagnosis_included is None\n",
    "    if do_drop_useless:\n",
    "        diagnosis = comorb.MHDECOD.value_counts()\n",
    "\n",
    "        mandatory_diagnosis = pandas.Index([\"CANCER PAIN\",\n",
    "                                            \"PROSTATE CANCER\"])\n",
    "        diagnosis_included = diagnosis[(diagnosis > 20) | (diagnosis.index.isin(mandatory_diagnosis))]\n",
    "\n",
    "    mask = comorb.MHDECOD.isin(diagnosis_included.index)\n",
    "    comorb_grouped = comorb.loc[mask, ['RPT', 'MHDECOD', 'MHSTDT_P']].groupby(['RPT', 'MHDECOD'])\n",
    "\n",
    "    n_comorbidities = comorb_grouped.size()\n",
    "    n_comorbidities.name = 'size'\n",
    "    n_comorbidities.fillna(value=0, inplace=True)\n",
    "\n",
    "    n_date = comorb_grouped['MHSTDT_P'].min()\n",
    "    n_date.name = 'date'\n",
    "\n",
    "    s1 = n_comorbidities.reset_index().pivot(index='RPT', columns='MHDECOD', values='size')\n",
    "    has_comorb = (s1 > 0)\n",
    "    comorb_dates = n_date.reset_index().pivot(index='RPT', columns='MHDECOD', values='date')\n",
    "    # Split date into quartiles\n",
    "    if date_quantiles is None:\n",
    "        comorb_dates_q, date_quantiles = cut_quantiles(comorb_dates, 4)\n",
    "    else:\n",
    "        comorb_dates_q, _ = cut_quantiles(comorb_dates, date_quantiles)\n",
    "\n",
    "    # Only available for CELGENE, but we want exact date\n",
    "    if \"PROSTATE CANCER\" in comorb_dates.columns:\n",
    "        comorb_dates_q[\"PROSTATE CANCER\"] = safe_anscombe(comorb_dates[\"PROSTATE CANCER\"])\n",
    "\n",
    "    if \"CANCER PAIN\" in comorb_dates.columns:\n",
    "        comorb_dates_q[\"CANCER PAIN\"] = safe_anscombe(comorb_dates[\"CANCER PAIN\"])\n",
    "\n",
    "    if not do_drop_useless:\n",
    "        d = diagnosis_included.index.difference(has_comorb.columns)\n",
    "        new_comorb = pandas.DataFrame(False, index=has_comorb.index, columns=d)\n",
    "        has_comorb = safe_concat((has_comorb, new_comorb), axis=1)\n",
    "\n",
    "        new_dates = pandas.DataFrame(\"NONE\", index=has_comorb.index, columns=d)\n",
    "        if \"CANCER PAIN\" in d:\n",
    "            new_dates[\"CANCER PAIN\"] = pandas.Series(0, index=has_comorb.index, name=\"CANCER PAIN\", dtype=float)\n",
    "        if \"PROSTATE CANCER\" in d:\n",
    "            new_dates[\"PROSTATE CANCER\"] = pandas.Series(0, index=has_comorb.index, name=\"PROSTATE PAIN\", dtype=float)\n",
    "\n",
    "        comorb_dates_q = safe_concat((comorb_dates_q, new_dates), axis=1)\n",
    "\n",
    "    pre_comorbidities = safe_concat((has_comorb,\n",
    "                                     comorb_dates_q.add_suffix(' date')), axis=1)\n",
    "\n",
    "    is_celgene = pre_comorbidities.index.to_series().str.startswith(\"CELG\")\n",
    "    pre_comorbidities[\"PROSTATE CANCER\"] = pre_comorbidities[\"PROSTATE CANCER\"].astype(object)\n",
    "    pre_comorbidities.loc[-is_celgene, \"PROSTATE CANCER\"] = None\n",
    "    pre_comorbidities['N comorbidities'] = safe_anscombe(comorb.groupby('RPT').size())\n",
    "\n",
    "    if do_drop_useless:\n",
    "        drop_useless(pre_comorbidities, suffix=[\"date\"], inplace=True)\n",
    "        mask = diagnosis_included.index.isin(pre_comorbidities.columns)\n",
    "        diagnosis_included = diagnosis_included[mask]\n",
    "    \n",
    "    return pre_comorbidities, diagnosis_included, date_quantiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pre_comorbidities, diagnosis_included, diagnosis_date_included = read_medhistory_table(join(base_dir, filenames[4]))\n",
    "print(pre_comorbidities.shape)\n",
    "diagnosis_included"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pre_comorbidities_test, _, _ = read_medhistory_table(join(test_base_dir, test_filenames[4]),\n",
    "                                                  diagnosis_included,\n",
    "                                                  diagnosis_date_included)\n",
    "assert len(pre_comorbidities.columns.sym_diff(pre_comorbidities_test.columns)) == 0\n",
    "pre_comorbidities_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LesionMeasure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LesionMeasure is a longitudinal data table that includes event level data.\n",
    "\n",
    "*Missing Data*: StudyID=\"ASCENT2\" did not provide event level lesion data, it only provides summary level lesion location variables, which have been included in CoreTable. Therefore, there are no event level data for ASCENT2 in this table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_count(x):\n",
    "    if pandas.isnull(x).all():\n",
    "        return x\n",
    "\n",
    "    s = x.notnull().sum()\n",
    "    if s == 0:\n",
    "        return \"0\"\n",
    "    elif s == 1:\n",
    "        return \"1\"\n",
    "    else:\n",
    "        return \"2+\"\n",
    "\n",
    "\n",
    "def get_presence(x):\n",
    "    if pandas.isnull(x).all():\n",
    "        return x\n",
    "\n",
    "    return (x == \"YES\").any()\n",
    "\n",
    "\n",
    "def aggregate_lesion_measure(frame, column, count=False):\n",
    "    grouped = frame.groupby([\"RPT\", column])\n",
    "\n",
    "    if count:\n",
    "        func = get_count\n",
    "        na_value = \"0\"\n",
    "    else:\n",
    "        func = get_presence\n",
    "        na_value = False\n",
    "\n",
    "    measure = grouped['LSSTRESC'].aggregate(func)\n",
    "    measure.name = 'value'\n",
    "    values = measure.reset_index().pivot(index='RPT', columns=column, values='value')\n",
    "    values.fillna(na_value, inplace=True)\n",
    "    if count:\n",
    "        values = values.apply(lambda x: to_ordered_categorical(x, [\"0\", \"1\", \"2+\"]))\n",
    "\n",
    "    return values\n",
    "\n",
    "\n",
    "def read_lesionmeasure_table(filename, locations_included=None, date_quantiles=None):\n",
    "    lesion = read_csv(filename)\n",
    "\n",
    "    if numpy.issubdtype(lesion.VISIT, numpy.int):\n",
    "        lesion_baseline_mask = lesion.VISIT == 1\n",
    "    else:\n",
    "        lesion_baseline_mask = lesion.VISIT == 'SCREENING'\n",
    "\n",
    "    lesion_baseline = lesion.loc[lesion_baseline_mask, :]\n",
    "    \n",
    "    check_units_consistency(lesion_baseline, 'LSLOC', 'LSSTRESU')\n",
    "\n",
    "    lesion_baseline.LSLOC.replace({\"LUNG\": \"LUNGS\",\n",
    "                                   \"OTHER NON-MEASUREABLE DISEASE - BONE LESIONS\": \"BONE\",\n",
    "                                   \"OTHER NON-MEASUREABLE DISEASE - PLEURAL EFFUSION\": \"PLEURA\"}, inplace=True)\n",
    "\n",
    "    # Fill missing values in LSLOC2 from LSLOC\n",
    "    lesion_baseline.LSLOC2.fillna(lesion_baseline.LSLOC, inplace=True)\n",
    "\n",
    "    do_drop_useless = locations_included is None\n",
    "    if do_drop_useless:\n",
    "        locations = lesion_baseline.LSLOC2.value_counts()\n",
    "        locations_included = locations[locations > 10]\n",
    "\n",
    "    # LSTESTCD == \"LENGTH\" is only defined for target lesions\n",
    "    # LSTESTCD == \"PRESENCE\" is only defined for non-target lesions\n",
    "    # check whether target or non-target lesion in respective organ is present\n",
    "    mask = lesion_baseline.LSLOC.isin(locations_included.index)\n",
    "    assert mask.any()\n",
    "\n",
    "    # count number of lesions\n",
    "    lesion_count = aggregate_lesion_measure(lesion_baseline.loc[mask, ['RPT', 'LSLOC2', 'LSSTRESC', 'LSDT_PC']],\n",
    "                                            \"LSLOC2\", count=True)\n",
    "\n",
    "    n_date = lesion_baseline.loc[mask, ['RPT', 'LSLOC2', 'LSDT_PC']].groupby(['RPT', 'LSLOC2']).min()\n",
    "    n_date.rename(columns={\"LSDT_PC\": \"date\"}, inplace=True)\n",
    "\n",
    "    dates = n_date.reset_index().pivot(index='RPT', columns='LSLOC2', values='date')\n",
    "    # Split date into quartiles\n",
    "    if date_quantiles is None:\n",
    "        lesion_date, date_quantiles = cut_quantiles(dates, 4)\n",
    "    else:\n",
    "        lesion_date, _ = cut_quantiles(dates, date_quantiles)\n",
    "\n",
    "    if not do_drop_useless:\n",
    "        d = locations_included.index.difference(lesion_count.columns)\n",
    "        new_locations = pandas.DataFrame(\"0\", index=lesion_count.index, columns=d)\n",
    "        new_locations = new_locations.apply(lambda x: to_ordered_categorical(x, [\"0\"]))\n",
    "        lesion_count = safe_concat((lesion_count, new_locations), axis=1)\n",
    "\n",
    "        new_dates = pandas.DataFrame(\"NONE\", index=lesion_date.index, columns=d)\n",
    "        new_dates = new_dates.apply(lambda x: to_ordered_categorical(x, [\"NONE\"]))\n",
    "        lesion_date = safe_concat((lesion_date, new_dates), axis=1)\n",
    "\n",
    "    pre_lesions = safe_concat((lesion_count,\n",
    "                               lesion_date.add_suffix(' date')), axis=1)\n",
    "\n",
    "    # min/max length of target lesion\n",
    "    length_mask = lesion_baseline.LSTESTCD == \"LENGTH\"\n",
    "    if (lesion_baseline.LSSTRESU.dropna() == \"CM\").all():\n",
    "        # convert CM to MM\n",
    "        values = lesion_baseline.loc[length_mask, \"LSSTRESC\"].map(lambda x: float(x) * 10.)\n",
    "        lesion_length = pandas.concat((lesion_baseline.loc[length_mask, \"RPT\"], values), axis=1)\n",
    "    else:\n",
    "        lesion_length = lesion_baseline.loc[length_mask, [\"RPT\", \"LSSTRESN\"]]\n",
    "\n",
    "    length_grouped = lesion_length.groupby('RPT')\n",
    "    pre_lesions[\"MIN LESION SIZE\"] = length_grouped.min()\n",
    "    pre_lesions[\"MAX LESION SIZE\"] = length_grouped.max()\n",
    "\n",
    "    def _fillna(x):\n",
    "        if pandas.core.common.is_numeric_dtype(x.dtype):\n",
    "            return x.fillna(0)\n",
    "        elif pandas.core.common.is_categorical_dtype(x.dtype):\n",
    "            return x.fillna(x.cat.categories[0])\n",
    "\n",
    "        assert x.notnull().all()\n",
    "        return x\n",
    "\n",
    "    pre_lesions = pre_lesions.apply(_fillna, axis=0)\n",
    "\n",
    "    n_target = lesion_baseline.loc[lesion_baseline.LSCAT == \"TARGET\", :].groupby('RPT').size()\n",
    "    bins = numpy.concatenate((numpy.arange(6), [float(\"inf\")]))\n",
    "    labels = [\"{0} lesions\".format(i)  for i in range(5)] + [\">=5 lesions\"]\n",
    "    pre_lesions['N target lesions'] = pandas.cut(n_target, bins, labels=labels,\n",
    "                                                 right=False, include_lowest=True)\n",
    "    pre_lesions['N target lesions'].fillna(\"0 lesions\", inplace=True)\n",
    "\n",
    "    n_non_target = lesion_baseline.loc[lesion_baseline.LSCAT == \"NON-TARGET\", :].groupby('RPT').size()\n",
    "    bins = numpy.concatenate((numpy.arange(11), [float(\"inf\")]))\n",
    "    labels = [\"{0} lesions\".format(i) for i in range(10)] + [\">=10 lesions\"]\n",
    "    pre_lesions['N non-target lesions'] = pandas.cut(n_non_target, bins, labels=labels,\n",
    "                                                     right=False, include_lowest=True)\n",
    "    pre_lesions['N non-target lesions'].fillna(\"0 lesions\", inplace=True)\n",
    "\n",
    "    if do_drop_useless:\n",
    "        drop_useless(pre_lesions, suffix=[\"date\"], inplace=True)\n",
    "        mask = locations_included.index.isin(pre_lesions.columns)\n",
    "        locations_included = locations_included[mask]\n",
    "    \n",
    "    return pre_lesions, locations_included, date_quantiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pre_lesions, locations_included, location_data_quantiles = read_lesionmeasure_table(\n",
    "    join(base_dir, filenames[1]))\n",
    "print(pre_lesions.shape)\n",
    "locations_included"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pre_lesions_test, _, _ = read_lesionmeasure_table(join(test_base_dir, test_filenames[1]),\n",
    "                                                  locations_included, location_data_quantiles)\n",
    "assert len(pre_comorbidities.columns.sym_diff(pre_comorbidities_test.columns)) == 0\n",
    "pre_lesions_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Concatenate Tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pre_meds = pre_meds.add_prefix('PreMed ')\n",
    "pre_lab = pre_lab.add_prefix('Lab ')\n",
    "pre_comorbidities = pre_comorbidities.add_prefix('MedHistory ')\n",
    "pre_vitals = pre_vitals.add_prefix('VitalSign ')\n",
    "pre_lesions = pre_lesions.add_prefix('LesionMeasure ')\n",
    "\n",
    "pre_meds_test = pre_meds_test.add_prefix('PreMed ')\n",
    "pre_lab_test = pre_lab_test.add_prefix('Lab ')\n",
    "pre_comorbidities_test = pre_comorbidities_test.add_prefix('MedHistory ')\n",
    "pre_vitals_test = pre_vitals_test.add_prefix('VitalSign ')\n",
    "pre_lesions_test = pre_lesions_test.add_prefix('LesionMeasure ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_all = safe_concat((core,\n",
    "                         pre_meds,\n",
    "                         pre_lab,\n",
    "                         pre_comorbidities,\n",
    "                         pre_vitals,\n",
    "                         pre_lesions), axis=1)\n",
    "test_all = safe_concat((core_test,\n",
    "                        pre_meds_test,\n",
    "                        pre_lab_test,\n",
    "                        pre_comorbidities_test,\n",
    "                        pre_vitals_test,\n",
    "                        pre_lesions_test), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have to ensure that categorical variables have the same categories for training and testing data even if some of the categories do not appear in the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_reg = pandas.Categorical(train_all[\"REGION_C\"], ordered=False)\n",
    "test_reg = pandas.Categorical(test_all[\"REGION_C\"], ordered=False)\n",
    "new_regions = test_reg.categories.difference(train_reg.categories)\n",
    "\n",
    "# Encode regions we never saw during training as 'OTHER'\n",
    "updates = {\"REGION_C\": {s: \"OTHER\" for s in new_regions}}\n",
    "if \"elevated\" in test_all['Lab LYM range'].unique():\n",
    "    test_all[\"Lab LYM range\"].cat.remove_categories(\"elevated\", inplace=True)\n",
    "\n",
    "if \"normal\" in test_all['Lab LYM range'].unique():\n",
    "    test_all[\"Lab SPGRV range\"].cat.remove_categories(\"normal\", inplace=True)\n",
    "\n",
    "test_all.replace(updates, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_cat = train_all.select_dtypes(include=[\"object\", \"category\"])\n",
    "test_cat = test_all.select_dtypes(include=[\"object\", \"category\"])\n",
    "\n",
    "columns = train_cat.columns.copy().union(test_cat.columns)\n",
    "\n",
    "for col in columns:\n",
    "    if col in {'AGEGRP', 'STUDYID'}:\n",
    "        continue\n",
    "\n",
    "    if col in test_cat.columns and col in train_cat.columns:\n",
    "        if pandas.core.common.is_categorical_dtype(train_cat[col].dtype) and pandas.core.common.is_object_dtype(test_cat[col].dtype):\n",
    "            rcat = train_cat[col].cat\n",
    "            test_all[col] = pandas.Categorical(test_cat[col],\n",
    "                                               categories=rcat.categories, ordered=rcat.ordered)\n",
    "\n",
    "        if test_all[col].dtype != train_all[col].dtype:\n",
    "            raise TypeError(\"%s: dtype mismatch: %s vs. %s\" % (col, test_all[col].dtype, train_all[col].dtype))\n",
    "\n",
    "        if pandas.core.common.is_categorical_dtype(test_all[col].dtype):\n",
    "            if test_all[col].cat.ordered != train_all[col].cat.ordered:\n",
    "                raise ValueError(\"%s: disagreement on whether category is ordered: \"\n",
    "                                 \"%s vs. %s\" % (test_all[col].cat.ordered, train_all[col].cat.ordered))\n",
    "\n",
    "            if test_all[col].cat.categories.equals(train_all[col].cat.categories):\n",
    "                continue\n",
    "                \n",
    "            cats_test = test_all[col].cat.categories\n",
    "            cats_train = train_all[col].cat.categories\n",
    "            ordered = test_all[col].cat.ordered\n",
    "        else:\n",
    "            if pandas.notnull(test_all[col]).any():\n",
    "                cats_test = set(test_all[col].dropna().unique())\n",
    "            else:\n",
    "                cats_test = set()\n",
    "                \n",
    "            if pandas.notnull(train_all[col]).any():\n",
    "                cats_train = set(train_all[col].dropna().unique())\n",
    "            else:\n",
    "                cats_train = set()\n",
    "                \n",
    "            ordered = False\n",
    "\n",
    "        no_train_cats = cats_test.difference(cats_train)\n",
    "        if len(no_train_cats) > 0:\n",
    "            print(\"%s: %d categories are not in training data: %s\" % (col, len(no_train_cats), no_train_cats))\n",
    "\n",
    "        cats = sorted(list(cats_train.union(cats_test)))\n",
    "#        print(\"%s -> categories=%s, ordered=%s\" % (col, cats, ordered))\n",
    "\n",
    "        test_new = pandas.Categorical(test_all[col].astype(\"object\"),\n",
    "                                      categories=cats, ordered=ordered)\n",
    "\n",
    "        train_new = pandas.Categorical(train_all[col].astype(\"object\"),\n",
    "                                       categories=cats, ordered=ordered)\n",
    "        \n",
    "        test_all[col] = pandas.Series(test_new, index=test_all[col].index, name=test_all[col].name)\n",
    "        train_all[col] = pandas.Series(train_new, index=train_all[col].index, name=train_all[col].name)\n",
    "\n",
    "_, updates = transfer_categories(train_all, test_all)\n",
    "assert len(updates) == 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Drop categorical columns with only one category having more than 10 samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "drop_cat_columns = []\n",
    "for col in columns:\n",
    "    if col in train_cat.columns and (train_cat[col].value_counts() >= 10).sum() <= 1:\n",
    "        drop_cat_columns.append(col)\n",
    "\n",
    "print(\"Dropping %d categorical columns\" % len(drop_cat_columns))\n",
    "train_all.drop(drop_cat_columns, axis=1, inplace=True)\n",
    "\n",
    "test_all.drop(test_all.columns.intersection(drop_cat_columns), axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Partition data according to studies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_test_all = safe_concat((train_all.copy(), test_all.copy()))\n",
    "\n",
    "print(train_all.shape)\n",
    "print(test_all.shape)\n",
    "print(train_test_all.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Count how often features are available from one study, but not the others. Since we have three studies, the maximum number of patterns is 8."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "variables = train_test_all.columns - ['STUDYID']\n",
    "missing_values = get_missing_values_per_study(train_test_all, variables, only_missing=False)\n",
    "# if feature has more than 80% missing, we count it as completely missing\n",
    "missing_values_mask = missing_values > .8\n",
    "\n",
    "def _mask_to_int(x):\n",
    "    val = 0\n",
    "    for i, b in enumerate(x):\n",
    "        if b:\n",
    "            val |= 1 << i\n",
    "    return val\n",
    "\n",
    "missing_patterns = missing_values_mask.apply(_mask_to_int, axis=1, reduce=True)\n",
    "missing_patterns.name = 'pattern'\n",
    "counts = missing_patterns.value_counts()\n",
    "counts.name = 'count'\n",
    "\n",
    "pattern_map = {}\n",
    "for p in itertools.product(range(2), repeat=4):\n",
    "    val = 0\n",
    "    for i, b in enumerate(p):\n",
    "        if b != 0:\n",
    "            val |= 1 << i\n",
    "    pattern_map[val] = pandas.Series(p, index=missing_values_mask.columns, dtype=bool)\n",
    "\n",
    "pattern_masks = pandas.DataFrame(pattern_map).T\n",
    "count_patterns_full = pandas.concat((counts, pattern_masks), axis=1)\n",
    "count_patterns_full.sort('count', ascending=False)\n",
    "count_patterns = count_patterns_full[count_patterns_full.AZ == False]\n",
    "count_patterns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Writing Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def print_stats(df, useless_cols):\n",
    "    print(\"%d useless columns\" % len(useless_cols))\n",
    "    print(\"shape = (%d, %d)\" % df.shape)\n",
    "    m = pandas.isnull(df).sum(axis=1)\n",
    "    n_complete_samples = (m == 0).sum()\n",
    "    p_missing = 100. * m.sum() / numpy.prod(df.shape)\n",
    "    print(\"%.2f%% total missing values \" % p_missing)\n",
    "    print(\"%d (%.2f%%) complete samples\" % (n_complete_samples, 100. * n_complete_samples / df.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def partition_data(data_all, data_partition, max_missing=0.3, drop_extra_columns={}):\n",
    "    study_prefix = {'EFC6546': 'VEN-', 'CELGENE': 'CELG-', 'ASCENT2': 'ASC'}\n",
    "    patient_id = data_all.index.to_series()\n",
    "\n",
    "    n_rows, n_cols = data_partition.shape\n",
    "    cols = data_partition.columns\n",
    "\n",
    "    datasets = {}\n",
    "    for i in range(n_rows):\n",
    "        row = data_partition.iloc[i, :]\n",
    "        patients_included = set()\n",
    "        names = []\n",
    "        for j in range(n_cols):\n",
    "            if row.iloc[j]:\n",
    "                prefix = study_prefix[cols[j]]\n",
    "                study_mask = patient_id.str.startswith(prefix)\n",
    "                patients_included.update(data_all[study_mask].index)\n",
    "                names.append(cols[j])\n",
    "\n",
    "        if len(patients_included) > 0:\n",
    "            key = \"_\".join(names)\n",
    "            print(key)\n",
    "\n",
    "            part_data_full = data_all.loc[patients_included, :]\n",
    "            m = part_data_full.apply(lambda x: pandas.isnull(x).sum())\n",
    "            m /= part_data_full.shape[0]\n",
    "\n",
    "            useless_cols = m[m > max_missing].index\n",
    "            if key in drop_extra_columns:\n",
    "                useless_cols = useless_cols.union(pandas.Index(drop_extra_columns[key]))\n",
    "\n",
    "            part_data = drop_useless(part_data_full, useless_cols=useless_cols,\n",
    "                                     suffix=[\"date\", \"range\", \"duration\"])\n",
    "\n",
    "            print_stats(part_data, part_data_full.columns.difference(part_data.columns))\n",
    "            print()\n",
    "            \n",
    "            datasets[key] = part_data\n",
    "\n",
    "    return datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "drop_extra = {\"ASCENT2\": [\"REGION_C\"],\n",
    "              \"ASCENT2_CELGENE_EFC6546\": [\"Lab log TESTO\", \"Lab log TESTO range\", \"Lab log TESTO date\",\n",
    "                                          \"Lab log PROTUR range\"],\n",
    "              \"ASCENT2_CELGENE\": [\"Lab log TESTO range\"],\n",
    "              \"CELGENE\": [\"Lab PH\", \"LesionMeasure ADRENAL\", \"Lab log UROBIL\", \"Lab log UROBIL date\"],\n",
    "              \"CELGENE_EFC6546\": [\"CCRC\", \"Lab CCRC\", \"Lab CCRC date\", \"Lab CCRC range\",\n",
    "                                  \"Lab log PROTUR range\", \"Lab log TESTO range\"],\n",
    "              \"EFC6546\": [\"Lab UREA\", \"Lab UREA date\", \"Lab UREA range\", \"Lab log UPCR\", \"Lab log UPCR date\"]}\n",
    "\n",
    "data_frames_new = partition_data(train_all.copy(), -pattern_masks[pattern_masks.AZ].drop(\"AZ\", axis=1),\n",
    "                                 drop_extra_columns=drop_extra)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for filename, dat in data_frames_new.items():\n",
    "    writearff(safe_concat((dat, train_q1_labels.loc[dat.index, :], train_q2_labels.loc[dat.index, :]), axis=1),\n",
    "                   filename + \".arff\", index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "writearff(safe_concat((train_all, train_q1_labels, train_q2_labels), axis=1), 'dream_train_all.arff', index=True)\n",
    "writearff(test_all, 'dream_test_all.arff', index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Diagnostic Plots and Statistics (Optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import matplotlib\n",
    "matplotlib.use('Agg')\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn\n",
    "seaborn.set(style='whitegrid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def concat_train_test(data_train, data_test, add_studyid=True):\n",
    "    train_part = train_all.loc[:, data_train.columns]\n",
    "    test_part = test_all.loc[:, data_test.columns]\n",
    "    if add_studyid:\n",
    "        train_part = safe_concat((train_all.STUDYID, train_part), axis=1)\n",
    "        test_part = safe_concat((test_all.STUDYID, test_part), axis=1)\n",
    "\n",
    "    df = safe_concat((train_part, test_part))\n",
    "    return df\n",
    "\n",
    "core_train_test = concat_train_test(core, core_test, add_studyid=False)\n",
    "meds_train_test = concat_train_test(pre_meds, pre_meds_test)\n",
    "lab_train_test = concat_train_test(pre_lab, pre_lab_test)\n",
    "comorbidities_train_test = concat_train_test(pre_comorbidities, pre_comorbidities_test)\n",
    "vitals_train_test = concat_train_test(pre_vitals, pre_vitals_test)\n",
    "lesions_train_test = concat_train_test(pre_lesions, pre_lesions_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compare_distributions(core_all, n_cols=5, figsize=(20, 22)):\n",
    "    core_numeric = core_all.select_dtypes(include=[numpy.number])\n",
    "    if core_numeric.shape[1] == 0:\n",
    "        raise ValueError('DataFrame has no float columns')\n",
    "\n",
    "    studies = core_all.STUDYID.unique()\n",
    "    studies.sort()\n",
    "    colors = seaborn.color_palette(n_colors=len(studies))\n",
    "    colors = [seaborn.utils.desaturate(c, .7) for c in colors]\n",
    "    color_map = dict([(studies[i], colors[i]) for i in range(len(studies))])\n",
    "\n",
    "    plt.figure(figsize=figsize)\n",
    "    n_rows = math.ceil(core_numeric.shape[1] / n_cols)\n",
    "    for i, col in enumerate(core_numeric.columns):\n",
    "        ax = plt.subplot(n_rows, n_cols, i + 1)\n",
    "        v = core_all.loc[:, [col, 'STUDYID']].dropna()\n",
    "        if v.shape[0] == 0:\n",
    "            print(col + ' is empty')\n",
    "            continue\n",
    "        _studies = v.iloc[:, 1].unique()\n",
    "        _col = [color_map[c] for c in _studies]\n",
    "\n",
    "        seaborn.violinplot(v.iloc[:, 0], groupby=v.iloc[:, 1], ax=ax, color=_col)\n",
    "        ax.set_title(col)\n",
    "        ax.set_ylabel(\"\")\n",
    "        ax.set_xlabel(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "compare_distributions(core_train_test)\n",
    "plt.tight_layout()\n",
    "plt.savefig('CoreTable-features-plot.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "compare_distributions(lab_train_test, n_cols=5, figsize=(20, 40))\n",
    "plt.tight_layout()\n",
    "plt.savefig('LabValue-features-plot.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "compare_distributions(vitals_train_test, figsize=(16, 7))\n",
    "plt.tight_layout()\n",
    "plt.savefig('VitalSign-features-plot.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "compare_distributions(lesions_train_test, figsize=(16, 6))\n",
    "plt.tight_layout()\n",
    "plt.savefig('LesionMeasure-features-plot.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def missing_values_heatmap(table, variables, only_missing=True, figsize=None):\n",
    "    values = get_missing_values_per_study(table, variables, only_missing=only_missing)\n",
    "\n",
    "    if figsize is None:\n",
    "        figsize = (1.5 * values.shape[1], .5 * values.shape[0])\n",
    "\n",
    "    plt.figure(figsize=figsize)\n",
    "    return seaborn.heatmap(values, annot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "variables = core_train_test.columns - ['STUDYID']\n",
    "missing_values_heatmap(core_train_test, variables)\n",
    "plt.tight_layout()\n",
    "plt.savefig('CoreTable-missing-values.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "variables = lab_train_test.columns - ['STUDYID']\n",
    "missing_values_heatmap(lab_train_test, variables)\n",
    "plt.tight_layout()\n",
    "plt.savefig('LabValue-missing-values.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "variables = comorbidities_train_test.columns - ['STUDYID']\n",
    "missing_values_heatmap(comorbidities_train_test, variables, figsize=(7, 40))\n",
    "plt.tight_layout()\n",
    "plt.savefig('MedHistory-missing-values.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "variables = lesions_train_test.columns - ['STUDYID']\n",
    "missing_values_heatmap(lesions_train_test, variables)\n",
    "plt.tight_layout()\n",
    "plt.savefig('LesionMeasure-missing-values.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "variables = train_test_all.columns - ['STUDYID']\n",
    "missing_values_heatmap(train_test_all, variables, figsize=(9, 90))\n",
    "plt.tight_layout()\n",
    "plt.savefig('All-missing-values.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "n_partitions = len(data_frames_new)\n",
    "names = sorted(list(data_frames_new.keys()))\n",
    "cross_tab = pandas.DataFrame(numpy.zeros((n_partitions, n_partitions), dtype=int),\n",
    "                             index=names, columns=names)\n",
    "\n",
    "for nam1 in names:\n",
    "    df1 = data_frames_new[nam1]\n",
    "    for nam2 in names:\n",
    "        if nam1 == nam2:\n",
    "            continue\n",
    "        df2 = data_frames_new[nam2]\n",
    "        diff = df1.columns.sym_diff(df2.columns)\n",
    "        cross_tab.loc[nam1, nam2] = len(diff)\n",
    "\n",
    "seaborn.heatmap(cross_tab, annot=True, fmt=\"d\", square=True)\n",
    "plt.title('Difference in features between partitions')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('difference-partitions.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%load_ext rpy2.ipython\n",
    "%R suppressMessages(library(VIM))\n",
    "from pandas.rpy.common import convert_to_r_dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def to_r_dataframe(dat):\n",
    "    short_columns = {}\n",
    "    for col in dat.columns:\n",
    "        if len(col) > 24:\n",
    "            newcol = col[:14] + \"..\" + col[-7:]\n",
    "        else:\n",
    "            newcol = col\n",
    "        short_columns[col] = newcol\n",
    "\n",
    "    idx = pandas.Index(short_columns.values())\n",
    "    if not idx.is_unique:\n",
    "        c = idx.value_counts()\n",
    "        dups = c[c > 1].index\n",
    "        upd = {}\n",
    "        checked = {}\n",
    "        for k, v in short_columns.items():\n",
    "            if v in dups:\n",
    "                num = checked[v] if v in checked else 1\n",
    "                upd[k] = v + \".%d\" % num\n",
    "                checked[v] = num + 1\n",
    "\n",
    "        short_columns.update(upd)\n",
    "        idx = pandas.Index(short_columns.values())\n",
    "\n",
    "    if not idx.is_unique:\n",
    "        raise ValueError('duplicate columns after shortening names')\n",
    "\n",
    "    dat = dat.rename(columns=short_columns)\n",
    "    for col in dat.select_dtypes(include=['category']).columns:\n",
    "        dat[col] = dat[col].astype(object, copy=False)\n",
    "\n",
    "    return convert_to_r_dataframe(dat, strings_as_factors=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%capture --no-stdout\n",
    "for filename, dat in data_frames_new.items():\n",
    "    rdat = to_r_dataframe(dat)\n",
    "    %Rpush rdat\n",
    "    %Rpush filename\n",
    "    %R pdf(paste(filename, \"pdf\", sep=\".\"), 18, 10); m <- aggr(rdat, plot=FALSE); plot(m, combined=TRUE, sortVars=TRUE, cex.axis=.3, numbers=TRUE, only.miss=TRUE); dev.off();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
